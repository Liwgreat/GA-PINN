{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6fc0cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:09.568250Z",
     "start_time": "2025-02-10T15:38:08.176043Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils_training import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f0d62eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.047502Z",
     "start_time": "2025-02-10T15:38:09.570529Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_inside: Column 0: range from -0.9996169610992423 to 0.9999084330058925\n",
      "t_inside: Column 0: range from 0.0006221087710398319 to 0.9998795647581709\n",
      "x_bound: Column 0: range from -0.9974393487799895 to 0.9951859062149828\n",
      "t_bound: Column 0: range from 0.0010549176968800646 to 0.9999568866549661\n"
     ]
    }
   ],
   "source": [
    "N_train = 1000\n",
    "N_bound = 200\n",
    "\n",
    "# x,t\n",
    "la = np.array([1,1])\n",
    "lb = np.array([-1,0])\n",
    "\n",
    "traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "\n",
    "x_inside = traindata[:,0:1]\n",
    "t_inside = traindata[:,1:2]\n",
    "\n",
    "x_inside = numpy_to_tensor(x_inside, var_name=\"x_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "t_inside = numpy_to_tensor(t_inside, var_name=\"t_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "\n",
    "x_bound = lb[0]+(la[0]-lb[0])*lhs(1,N_bound)\n",
    "t_bound = lb[1]+(la[1]-lb[1])*lhs(1,N_bound)\n",
    "\n",
    "x_bound = numpy_to_tensor(x_bound, var_name=\"x_bound\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)\n",
    "t_bound = numpy_to_tensor(t_bound, var_name=\"t_bound\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00bb6cfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.061025Z",
     "start_time": "2025-02-10T15:38:13.054898Z"
    },
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def exact_func(x_input):\n",
    "    x_value = x_input[:, 0:1]\n",
    "    t_value = x_input[:, 1:2]\n",
    "    \n",
    "    return  np.exp(-t_value) * np.sin(np.pi * x_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a14a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.070445Z",
     "start_time": "2025-02-10T15:38:13.063326Z"
    },
    "cell_style": "center"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observe_data: Column 0: range from -0.9616961099242215 to 0.9545653243224748\n",
      "observe_data: Column 1: range from 0.06221087710398319 to 0.9882641190636117\n",
      "observe_u: Column 0: range from -0.4622391171270676 to 0.6941402599252228\n",
      "observe_u: Column 0: range from -0.4622391171270676 to 0.6941402599252228\n",
      "J: 10\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1234\n",
    "np.random.seed(random_seed)\n",
    "observe_number = 10\n",
    "\n",
    "observe_data = lb+(la-lb)*lhs(2,observe_number)\n",
    "observe_clear_u = exact_func(observe_data)\n",
    "\n",
    "observe_u = observe_clear_u\n",
    "\n",
    "observe_data = numpy_to_tensor(observe_data, var_name=\"observe_data\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "observe_clear_u = numpy_to_tensor(observe_clear_u, var_name=\"observe_u\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "observe_u = numpy_to_tensor(observe_u, var_name=\"observe_u\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "print('J:',len(observe_u))\n",
    "\n",
    "observe_data_x_inside = observe_data[:,0:1]\n",
    "observe_data_t_inside = observe_data[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36e0637a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.084372Z",
     "start_time": "2025-02-10T15:38:13.072828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data: Column 0: range from -0.9999021346039978 to 0.999818369091213\n",
      "test_data: Column 1: range from 5.933244265166393e-06 to 0.9999791490405054\n",
      "test_u: Column 0: range from -0.9962151573581175 to 0.9967165533751065\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(5678)\n",
    "N_test_number = 10000\n",
    "\n",
    "test_data = lb+(la-lb)*lhs(2,N_test_number)\n",
    "test_u = exact_func(test_data)\n",
    "\n",
    "test_data = numpy_to_tensor(test_data, var_name=\"test_data\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "test_u = numpy_to_tensor(test_u, var_name=\"test_u\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "\n",
    "test_data_x_inside = test_data[:,0:1]\n",
    "test_data_t_inside = test_data[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1f0c2b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.090594Z",
     "start_time": "2025-02-10T15:38:13.086492Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_transform(x_input, y_input):\n",
    "    x_in = x_input[:, 0:1]\n",
    "    t_in = x_input[:, 1:2]\n",
    "\n",
    "    return (1 - x_in) * (1 + x_in) * (1 - torch.exp(-t_in)) * y_input + torch.sin(np.pi * x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8951027",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.096206Z",
     "start_time": "2025-02-10T15:38:13.093167Z"
    }
   },
   "outputs": [],
   "source": [
    "C1 = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b1a3785",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.104714Z",
     "start_time": "2025-02-10T15:38:13.098855Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_f(x_grad,t_grad,PINNs,C,return_sequence='not'):\n",
    "    \n",
    "    ########### loss f  ###########\n",
    "    E_inside = PINNs(torch.cat((x_grad,t_grad),axis=1))\n",
    "    E_inside = output_transform(torch.cat((x_grad,t_grad),axis=1),E_inside)\n",
    "    \n",
    "    u_xx = compute_higher_order_derivatives(E_inside, [x_grad,x_grad])\n",
    "    u_t = compute_higher_order_derivatives(E_inside, [t_grad])\n",
    "    \n",
    "    loss_f_sequence = u_t-C*u_xx+torch.exp(-t_grad)*(torch.sin(torch.tensor(np.pi)*x_grad)-torch.tensor(np.pi)*torch.tensor(np.pi)*torch.sin(torch.tensor(np.pi)*x_grad))\n",
    "    loss_f_squared_sequence = torch.square(loss_f_sequence)\n",
    "\n",
    "    if return_sequence=='yes':\n",
    "        return loss_f_squared_sequence\n",
    "    else:\n",
    "        return torch.mean(loss_f_squared_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd0a41cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.115104Z",
     "start_time": "2025-02-10T15:38:13.109220Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_bound(bound_x, bound_t, PINNs, C, return_sequence='not'):\n",
    "    \n",
    "    E_bound_x_zero = PINNs(torch.cat((bound_x,torch.zeros_like(bound_x)),axis=1)) \n",
    "    Exact_x_zero = torch.sin(torch.tensor(np.pi)*bound_x)\n",
    "    loss_bound_for_a = torch.mean(torch.square(E_bound_x_zero-Exact_x_zero))\n",
    "    \n",
    "    E_bound_fu_1_t = PINNs(torch.cat((-torch.ones_like(bound_t),bound_t),axis=1)) \n",
    "    loss_bound_for_b = torch.mean(torch.square(E_bound_fu_1_t))\n",
    "    \n",
    "    E_bound_1_t = PINNs(torch.cat((torch.ones_like(bound_t),bound_t),axis=1))\n",
    "    loss_bound_for_c = torch.mean(torch.square(E_bound_1_t))\n",
    "    \n",
    "    loss_bound_value = loss_bound_for_a+loss_bound_for_b+loss_bound_for_c\n",
    "    \n",
    "    return loss_bound_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40bb89d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.120474Z",
     "start_time": "2025-02-10T15:38:13.116844Z"
    }
   },
   "outputs": [],
   "source": [
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db0e0d93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.129251Z",
     "start_time": "2025-02-10T15:38:13.122373Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "net_settings_for_PINNs1 = NetSetting(input_dims=2, hidden_neurons_list=[20]*4, \n",
    "                                     output_dims=1, hidden_activation='tanh', \n",
    "                                     output_activation=None, initializer_method='xavier')\n",
    "PINNs1 = get_mlp_pinn(net_settings_for_PINNs1)\n",
    "PINNs1.cuda()\n",
    "\n",
    "initialize_weights(PINNs1, net_settings_for_PINNs1.initializer_method)\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)    \n",
    "optimizer1.add_param_group({'params': [C1], 'lr': 0.001})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4106b6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.134964Z",
     "start_time": "2025-02-10T15:38:13.131333Z"
    }
   },
   "outputs": [],
   "source": [
    "x_inside_all = torch.cat((x_inside,observe_data[:,0:1]),axis=0)\n",
    "t_inside_all = torch.cat((t_inside,observe_data[:,1:2]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "414b1840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.143281Z",
     "start_time": "2025-02-10T15:38:13.137193Z"
    }
   },
   "outputs": [],
   "source": [
    "net_settings_for_discriminator1 = NetSetting(input_dims=3, hidden_neurons_list=[20]*2, \n",
    "                                     output_dims=1, hidden_activation='sigmoid(tanh)', \n",
    "                                     output_activation='sigmoid(tanh)', initializer_method='xavier')\n",
    "\n",
    "discriminator1 = get_mlp_pinn(net_settings_for_discriminator1)\n",
    "discriminator1.cuda() \n",
    "initialize_weights(discriminator1, net_settings_for_discriminator1.initializer_method)\n",
    "\n",
    "optimizer2 = optim.Adam(discriminator1.parameters(), lr=1e-3,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d979101",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.149176Z",
     "start_time": "2025-02-10T15:38:13.145418Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_optimizer1(PINNs,C,discriminator):\n",
    "    \n",
    "    for param in PINNs.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    C.requires_grad = True\n",
    "    \n",
    "    for param in discriminator.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eebe420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.155008Z",
     "start_time": "2025-02-10T15:38:13.151588Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_optimizer2(PINNs,C,discriminator):\n",
    "    \n",
    "    for param in PINNs.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    C.requires_grad = False\n",
    "    \n",
    "    for param in discriminator.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff7e18f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:38:13.164126Z",
     "start_time": "2025-02-10T15:38:13.157147Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_for_gan(PINNs,C,discriminator,observe_data_input,observe_u_input):\n",
    "    \n",
    "    \n",
    "    ############ loss D ###########\n",
    "    train_optimizer2(PINNs,C,discriminator)\n",
    "    \n",
    "    pre_H = PINNs(observe_data_input)\n",
    "    pre_H = output_transform(observe_data_input,pre_H)\n",
    "    \n",
    "    d_fake = discriminator(torch.cat((observe_data_input,pre_H),1))\n",
    "    d_real = discriminator(torch.cat((observe_data_input,observe_u_input),1))\n",
    "\n",
    "    loss_D = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "\n",
    "    optimizer2.zero_grad()\n",
    "    loss_D .backward()\n",
    "    optimizer2.step()  \n",
    "\n",
    "    ############ loss G ###########\n",
    "    train_optimizer1(PINNs,C,discriminator)\n",
    "    \n",
    "    pre_H = PINNs(observe_data_input)\n",
    "    pre_H = output_transform(observe_data_input,pre_H)\n",
    "    \n",
    "    d_fake = discriminator(torch.cat((observe_data_input,pre_H),1))\n",
    "\n",
    "    loss_G = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - observe_u_input))\n",
    "\n",
    "    optimizer1.zero_grad()\n",
    "    loss_G.backward()\n",
    "    optimizer1.step()  \n",
    "    \n",
    "    return PINNs,C,discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d774dcc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:41:36.405347Z",
     "start_time": "2025-02-10T15:38:13.166532Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 train_loss: 103.55452728271484 test_loss: 0.6358123421669006\n",
      "tensor(2., requires_grad=True)\n",
      "It: 1000 train_loss: 0.3975432515144348 test_loss: 0.3690960705280304\n",
      "tensor(1.6688, requires_grad=True)\n",
      "It: 2000 train_loss: 0.16700394451618195 test_loss: 0.29866641759872437\n",
      "tensor(1.4787, requires_grad=True)\n",
      "It: 3000 train_loss: 0.03851306438446045 test_loss: 0.14255735278129578\n",
      "tensor(1.1894, requires_grad=True)\n",
      "It: 4000 train_loss: 0.0004233501385897398 test_loss: 0.009526378475129604\n",
      "tensor(1.0106, requires_grad=True)\n",
      "It: 5000 train_loss: 0.0001041708019329235 test_loss: 0.0026008484419435263\n",
      "tensor(1.0027, requires_grad=True)\n",
      "It: 6000 train_loss: 4.981114398106001e-05 test_loss: 0.001403145957738161\n",
      "tensor(1.0014, requires_grad=True)\n",
      "It: 7000 train_loss: 2.3611342840013094e-05 test_loss: 0.0010780708398669958\n",
      "tensor(1.0011, requires_grad=True)\n",
      "It: 8000 train_loss: 1.175664147012867e-05 test_loss: 0.0006254928885027766\n",
      "tensor(1.0006, requires_grad=True)\n",
      "It: 9000 train_loss: 7.884990736783948e-06 test_loss: 0.0004797330766450614\n",
      "tensor(1.0004, requires_grad=True)\n",
      "Final: train_loss: 0.0011791324941441417 test_loss: 0.01117940153926611\n"
     ]
    }
   ],
   "source": [
    "############## Record list ###############\n",
    "loss_all_1 = []\n",
    "loss_f_1 = []\n",
    "loss_f_for_collocation_1 = []\n",
    "loss_f_for_T_1 = []\n",
    "loss_f_excapt_T_1 = []\n",
    "loss_T_1 = []\n",
    "loss_T_clear_1 = []\n",
    "loss_T_1_test_data = []\n",
    "test_loss_1 = []\n",
    "C1_list = []\n",
    "############## Record list ###############\n",
    "\n",
    "nIter1 = 10000\n",
    "it = 0\n",
    "\n",
    "while it<nIter1:\n",
    "    \n",
    "    if it<6000:\n",
    "        ######### GAN  #########\n",
    "        PINNs1,C1,discriminator1 = train_for_gan(PINNs1,C1,discriminator1,observe_data,observe_u)  \n",
    "        \n",
    "    #########loss f#########    \n",
    "    loss_f = get_loss_f(x_inside_all,t_inside_all,PINNs1,C1,return_sequence='not')\n",
    "\n",
    "    #########loss observation#########        \n",
    "    E_observation = PINNs1(observe_data) \n",
    "    E_observation = output_transform(observe_data,E_observation)\n",
    "    loss_observation = torch.mean(torch.square(E_observation-observe_u))    \n",
    "\n",
    "    #########loss PI#########\n",
    "    loss = loss_f+10*loss_observation\n",
    "    \n",
    "    #########test_loss NRMSE#########\n",
    "    pre_u = PINNs1(test_data)\n",
    "    pre_u = output_transform(test_data,pre_u)\n",
    "    test_loss = relative_l2_torch(pre_u,test_u)\n",
    "    #########test_loss NRMSE#########\n",
    "    \n",
    "    #########Record#########\n",
    "    C1_list.append(C1.item())   \n",
    "    loss_T_1.append(loss_observation.item()) \n",
    "    test_loss_1.append(test_loss)\n",
    "    #########Record#########\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print('It:', it, 'train_loss:', loss.item(), 'test_loss:', test_loss)\n",
    "        print(C1)\n",
    "        \n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    it = it + 1   \n",
    "    \n",
    "print('Final:', 'train_loss:', loss.item(), 'test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da8195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e7106b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T15:41:36.420771Z",
     "start_time": "2025-02-10T15:41:36.408991Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "folder_path = '../experimental_data/GA_PINN/'\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "np.save(os.path.join(folder_path, 'loss_T_1.npy'), loss_T_1)\n",
    "np.save(os.path.join(folder_path, 'test_loss_1.npy'), test_loss_1)\n",
    "np.save(os.path.join(folder_path, 'C1_list.npy'), C1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f35505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
