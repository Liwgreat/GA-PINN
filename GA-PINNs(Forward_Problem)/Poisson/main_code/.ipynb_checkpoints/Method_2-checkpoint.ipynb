{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.526897Z",
     "start_time": "2024-02-06T04:13:51.304261Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.533712Z",
     "start_time": "2024-02-06T04:13:52.529121Z"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.544520Z",
     "start_time": "2024-02-06T04:13:52.537780Z"
    }
   },
   "outputs": [],
   "source": [
    "class hidden_layers(nn.Module):\n",
    "    def __init__(self,input_number,output_number):\n",
    "        super(hidden_layers, self).__init__()\n",
    "        self.layer = nn.Linear(input_number,output_number)\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = torch.sin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.553123Z",
     "start_time": "2024-02-06T04:13:52.547739Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN_H1 (nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        #depth = layers-2\n",
    "        super(NN_H1, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(nn.Linear(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(nn.Linear(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.560463Z",
     "start_time": "2024-02-06T04:13:52.555607Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN_H2 (nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        #depth = layers-2\n",
    "        super(NN_H2, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(hidden_layers(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(hidden_layers(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.568251Z",
     "start_time": "2024-02-06T04:13:52.562694Z"
    }
   },
   "outputs": [],
   "source": [
    "class get_discriminator(nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        #depth = layers-2\n",
    "        super(get_discriminator, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(hidden_layers(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(hidden_layers(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For PINNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.577093Z",
     "start_time": "2024-02-06T04:13:52.570690Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "N_train = 5000\n",
    "N_bound = 100\n",
    "\n",
    "np.random.seed(12345)\n",
    "X_train = np.random.uniform(0,1,(N_train,2))\n",
    "X_bound_zero_one = np.concatenate((np.zeros((int(N_bound/4),1)),np.ones((int(N_bound/4),1))),0)\n",
    "np.random.seed(123456)\n",
    "X_bound1 = np.concatenate((np.random.uniform(0,1,(int(N_bound/2),1)),X_bound_zero_one),1)\n",
    "np.random.seed(1234567)\n",
    "X_bound2 = np.concatenate((X_bound_zero_one,np.random.uniform(0,1,(int(N_bound/2),1))),1)\n",
    "\n",
    "X_bound = np.concatenate((X_bound1,X_bound2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.592940Z",
     "start_time": "2024-02-06T04:13:52.579461Z"
    }
   },
   "outputs": [],
   "source": [
    "#x,t  #u,v\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_bound = torch.from_numpy(X_bound).float()\n",
    "x = X_train[:,0:1]\n",
    "t = X_train[:,1:2]\n",
    "\n",
    "x.requires_grad_()\n",
    "t.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:52.603641Z",
     "start_time": "2024-02-06T04:13:52.599536Z"
    }
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "np.random.seed(1111)\n",
    "gan_data_x_t = lhs(2,n)\n",
    "gan_data_u = 1/(2*np.pi**2)*np.sin(gan_data_x_t[:,0:1]*np.pi)*np.sin(gan_data_x_t[:,1:2]*np.pi)\n",
    "gan_data_x_t = torch.from_numpy(gan_data_x_t).float()\n",
    "#gan_data_u = torch.sin(k*gan_data_x_t)\n",
    "gan_data_u = torch.from_numpy(gan_data_u).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image With Labeled Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:55.660009Z",
     "start_time": "2024-02-06T04:13:52.605185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "traindata = np.concatenate((np.linspace(0,1,200).reshape(-1,1),np.linspace(0,1,200).reshape(-1,1)),1)\n",
    "x_ = traindata[:,0:1]\n",
    "y_ = traindata[:,1:2]\n",
    "xx,yy = np.meshgrid(x_,y_)\n",
    "data_numpy = np.concatenate((xx.reshape(-1,1),yy.reshape(-1,1)),1)\n",
    "\n",
    "aa = 1/(2*np.pi**2)*np.sin(data_numpy[:,0]*np.pi)*np.sin(data_numpy[:,1]*np.pi)\n",
    "plt.imshow(aa.reshape(200,200), interpolation='nearest',extent=[0, 1, 0, 1], cmap='rainbow')#其实可以不加origin参数 对于这组数据相当于origin='upper'，其实就是按照数据原来的位置画图\n",
    "plt.colorbar(shrink=.98)\n",
    "plt.scatter(gan_data_x_t[:,0:1], gan_data_x_t[:,1:2],c='k',marker = 'x',alpha=1,s=15)\n",
    "plt.savefig('Possion h points.eps',format='eps',dpi=1000, bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:55.666379Z",
     "start_time": "2024-02-06T04:13:55.662734Z"
    }
   },
   "outputs": [],
   "source": [
    "def relative_l2(u_pred,u_real):\n",
    "    l2 = np.linalg.norm(u_real-u_pred,2)/np.linalg.norm(u_real,2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:13:55.675470Z",
     "start_time": "2024-02-06T04:13:55.668473Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "test_data = lhs(2,5000)\n",
    "test_data_tensor = torch.from_numpy(test_data).float()\n",
    "aa = 1/(2*np.pi**2)*np.sin(test_data[:,0]*np.pi)*np.sin(test_data[:,1]*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method2\n",
    "**$\\text { GA - PINN }$**\n",
    "\n",
    "<div class=\"alert alert-info\">`loss_function：`\n",
    "\n",
    "$\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\mathrm{L}_{\\text {PINN }}:=\\mathrm{L}_f+\\lambda_1 \\mathrm{~L}_b \\text { with } \\mathrm{L}_b:=\\sum_{i=1}^I \\mathrm{~L}_{b_i}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T04:15:34.912393Z",
     "start_time": "2024-02-06T04:13:55.677931Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs2 = NN_H2(2, 100, 4, 1)\n",
    "PINNs2.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs2.parameters()}], lr=1e-3)\n",
    "\n",
    "\n",
    "discriminator= get_discriminator(3, 100, 1, 1)\n",
    "discriminator.apply(weights_init)\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.01}], lr=5e-3)\n",
    "\n",
    "loss_all_2= []\n",
    "test_loss_2 = []\n",
    "\n",
    "#########gpu############\n",
    "discriminator.cuda()\n",
    "X_bound = X_bound.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "PINNs2.cuda()\n",
    "E_bound = PINNs2(X_bound)\n",
    "real_bound = torch.zeros_like(E_bound)\n",
    "real_bound = real_bound.cuda()\n",
    "x = x.cuda()\n",
    "t = t.cuda()\n",
    "#########gpu############\n",
    "\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while loss1_value > 5e-5 :\n",
    "    PINNs2.cuda()\n",
    "    \n",
    "    ##############loss D############\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    \n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "\n",
    "    \n",
    "    ##############loss G ############\n",
    "    for param_group in optimizer1.param_groups:\n",
    "        param_group[\"lr\"]=1e-6\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    loss_L = torch.mean(torch.square(pre_H - gan_data_u))+torch.mean(1-d_fake)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()  \n",
    "    \n",
    "    \n",
    "    \n",
    "    for param_group in optimizer1.param_groups:\n",
    "        param_group[\"lr\"]=1e-3 \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs2(X_bound)\n",
    "    real_bound = torch.zeros_like(E_bound)\n",
    "    loss_bound = torch.mean(torch.square(E_bound-real_bound))\n",
    "    \n",
    "    ##### loss f  ######\n",
    "    \n",
    "    E_inside = PINNs2(torch.cat((x,t),1))\n",
    "    E_x = autograd.grad(outputs=E_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx = autograd.grad(outputs=E_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(E_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_t = autograd.grad(outputs=E_inside, inputs=t,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_tt = autograd.grad(outputs=E_t, inputs=t,\n",
    "                              grad_outputs=torch.ones_like(E_t),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]       \n",
    "    deata_E = E_xx+E_tt\n",
    "    loss_f = torch.mean(torch.square(deata_E+torch.sin(torch.pi*x)*torch.sin(torch.pi*t)))\n",
    "    \n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    \n",
    "\n",
    "    loss_g = loss_f+loss_bound\n",
    "    \n",
    "    loss_p = loss_f+loss_bound\n",
    "    loss1_value = loss_p.item()\n",
    "\n",
    "    loss_all_2.append(loss1_value)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_g.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "  \n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs2.cpu()\n",
    "    test_loss = relative_l2(PINNs2(test_data_tensor).detach().numpy(),aa.reshape(-1,1))\n",
    "    test_loss_2.append(test_loss)\n",
    "    \n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss_p.item())\n",
    "    it = it + 1         \n",
    "loss_p.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:40:18.408179Z",
     "start_time": "2024-10-28T14:40:18.403154Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/method_2/test_loss_2',test_loss_2)\n",
    "# np.save('../experimental_data/method_2/loss_all_2',loss_all_2)\n",
    "# torch.save(PINNs2,'../saved_model/PINNs2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch and NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:40:18.755912Z",
     "start_time": "2024-10-28T14:40:18.695439Z"
    }
   },
   "outputs": [],
   "source": [
    "Epochs = len(test_loss_2)\n",
    "NRMSE = relative_l2(PINNs2(test_data_tensor).detach().numpy(),aa.reshape(-1,1))\n",
    "\n",
    "print('Epochs:',Epochs,'NRMSE:',NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
