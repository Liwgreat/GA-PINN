{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:22:53.944499Z",
     "start_time": "2024-03-05T15:22:52.641260Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For PINNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:22:53.956414Z",
     "start_time": "2024-03-05T15:22:53.947380Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "N_bound = 100\n",
    "\n",
    "np.random.seed(123)\n",
    "train_x_y_t = lhs(3,N_train)\n",
    "np.random.seed(12345)\n",
    "bound_x_y = lhs(2,N_bound)\n",
    "bound_x_y_t = np.concatenate((bound_x_y,np.zeros((N_bound,1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:22:53.973356Z",
     "start_time": "2024-03-05T15:22:53.958855Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3976],\n",
       "        [0.7691],\n",
       "        [0.9756],\n",
       "        ...,\n",
       "        [0.2023],\n",
       "        [0.6423],\n",
       "        [0.6873]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_y_t = torch.from_numpy(train_x_y_t).float()\n",
    "bound_x_y = torch.from_numpy(bound_x_y).float()\n",
    "bound_x_y_t = torch.from_numpy(bound_x_y_t).float()\n",
    "\n",
    "x = train_x_y_t[:,0:1]\n",
    "y = train_x_y_t[:,1:2]\n",
    "t = train_x_y_t[:,2:3]\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "t.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:22:53.980256Z",
     "start_time": "2024-03-05T15:22:53.977078Z"
    }
   },
   "outputs": [],
   "source": [
    "def relative_l2(u_pred,u_real):\n",
    "    l2 = np.linalg.norm(u_real-u_pred,2)/np.linalg.norm(u_real,2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:22:54.040293Z",
     "start_time": "2024-03-05T15:22:53.981886Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.integrate\n",
    "from numpy import exp\n",
    "from math import sqrt\n",
    "import math\n",
    "def InIn(x_y_t):\n",
    "    x1 = x_y_t[:,0:1]\n",
    "    x2 = x_y_t[:,1:2]\n",
    "    t = x_y_t[:,2:3]\n",
    "    P = np.zeros_like(t)\n",
    "    for i in range(len(t)):\n",
    "        f = lambda y1,y2 : exp(-((x1[i]-y1)**2+(x2[i]-y2)**2)/(4*t[i]))*(y1-y2)\n",
    "        p,err= scipy.integrate.dblquad(f, -np.inf, np.inf, lambda g : -np.inf, lambda h : np.inf)\n",
    "        P[i] = p/(4*np.pi*t[i])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:28:09.674506Z",
     "start_time": "2024-03-05T15:22:54.043205Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "test_x_y_t = lhs(3,500)\n",
    "x1 = test_x_y_t[:,0:1]\n",
    "x2 = test_x_y_t[:,1:2]\n",
    "t_ = test_x_y_t[:,2:3]\n",
    "test_u = np.zeros_like(t_)\n",
    "for i in range(len(t_)):\n",
    "    f = lambda y1,y2 : exp(-((x1[i]-y1)**2+(x2[i]-y2)**2)/(4*t_[i]))*(y1-y2)\n",
    "    p,err= scipy.integrate.dblquad(f, -np.inf, np.inf, lambda g : -np.inf, lambda h : np.inf)\n",
    "    test_u[i] = p/(4*np.pi*t_[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:28:09.685284Z",
     "start_time": "2024-03-05T15:28:09.679300Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x_y_t = torch.from_numpy(test_x_y_t).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:28:14.675663Z",
     "start_time": "2024-03-05T15:28:09.687272Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(234)\n",
    "n = 7\n",
    "gan_data_x_t = lhs(3,10)\n",
    "np.random.seed(1234)\n",
    "chosen_indices = np.random.choice(gan_data_x_t.shape[0], size=n, replace=False)\n",
    "gan_data_x_t = gan_data_x_t[chosen_indices, :]\n",
    "gan_data_u = InIn(gan_data_x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:28:14.685886Z",
     "start_time": "2024-03-05T15:28:14.680476Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_data_x_t = torch.from_numpy(gan_data_x_t).float()\n",
    "gan_data_u = torch.from_numpy(gan_data_u).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method2\n",
    "**$\\text { GA - PINN }$**\n",
    "\n",
    "<div class=\"alert alert-info\">`loss_functionï¼š`\n",
    "\n",
    "$\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\mathrm{L}_{\\text {PINN }}:=\\mathrm{L}_f+\\lambda_1 \\mathrm{~L}_b \\text { with } \\mathrm{L}_b:=\\sum_{i=1}^I \\mathrm{~L}_{b_i}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:51.397988Z",
     "start_time": "2024-03-05T15:28:14.688879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.15195555984973907\n",
      "It: 100 Loss: 0.0007198601961135864\n",
      "It: 200 Loss: 0.00042809784645214677\n",
      "It: 300 Loss: 8.154893293976784e-05\n",
      "It: 400 Loss: 0.0006989868124946952\n",
      "It: 500 Loss: 7.330749212997034e-05\n",
      "It: 600 Loss: 0.008985621854662895\n",
      "It: 700 Loss: 6.0282633057795465e-05\n",
      "It: 800 Loss: 2.7645863156067207e-05\n",
      "It: 900 Loss: 9.820659761317074e-05\n",
      "It: 1000 Loss: 3.2417039619758725e-05\n",
      "It: 1100 Loss: 7.193395140348002e-05\n",
      "It: 1200 Loss: 2.1585636204690672e-05\n",
      "It: 1300 Loss: 4.914974851999432e-05\n",
      "It: 1400 Loss: 1.70956009242218e-05\n",
      "It: 1500 Loss: 4.400056059239432e-05\n",
      "It: 1600 Loss: 4.28771018050611e-05\n",
      "It: 1700 Loss: 2.4547345674363896e-05\n",
      "It: 1800 Loss: 1.8145572539651766e-05\n",
      "It: 1900 Loss: 1.4480264326266479e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.993161383026745e-06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs2 = NN_H2(3, 100, 4, 1)\n",
    "PINNs2.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs2.parameters()}], lr=1e-3)\n",
    "\n",
    "discriminator= get_discriminator(4, 100, 1, 1)\n",
    "discriminator.apply(weights_init)\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.01}], lr=5e-3)\n",
    "\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "\n",
    "#########gpu############\n",
    "discriminator.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs2.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "#########gpu############\n",
    "\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs2.cuda()\n",
    "    \n",
    "    ##############loss D############\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    \n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "    ##############loss G ############\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    loss_L = torch.mean(torch.square(pre_H - gan_data_u))+torch.mean(1-d_fake)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()  \n",
    "\n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs2(bound_x_y_t)\n",
    "    \n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "  \n",
    "    ##### loss f  ######\n",
    "    \n",
    "    u_inside = PINNs2(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "    \n",
    "    loss = loss_bound+loss_f\n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_2.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs2.cpu()\n",
    "    test_loss =  relative_l2(PINNs2(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_2.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method3\n",
    "$\\text { PINN }^{\\dagger}$\n",
    "\n",
    "<div class=\"alert alert-info\">objective functionï¼š\n",
    "\n",
    "$\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:29:51.403899Z",
     "start_time": "2024-03-05T15:29:51.400239Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:34:35.694317Z",
     "start_time": "2024-03-05T15:29:51.405588Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.32263725996017456 testloss: 0.8965330564695154\n",
      "It: 100 Loss: 0.0015202356735244393 testloss: 0.10559595204279465\n",
      "It: 200 Loss: 0.0006329596508294344 testloss: 0.08554681313401764\n",
      "It: 300 Loss: 0.0002820867521222681 testloss: 0.07934313352959493\n",
      "It: 400 Loss: 0.00015041077858768404 testloss: 0.06199249985888745\n",
      "It: 500 Loss: 7.719704444753006e-05 testloss: 0.06413111518178459\n",
      "It: 600 Loss: 5.6425229558954015e-05 testloss: 0.06565948260090228\n",
      "It: 700 Loss: 4.550605081021786e-05 testloss: 0.06619041661412081\n",
      "It: 800 Loss: 0.0001011505737551488 testloss: 0.05192891131646021\n",
      "It: 900 Loss: 5.833639806951396e-05 testloss: 0.056377998041314506\n",
      "It: 1000 Loss: 4.3094867578474805e-05 testloss: 0.058506521256744375\n",
      "It: 1100 Loss: 3.538500459399074e-05 testloss: 0.05942567809679564\n",
      "It: 1200 Loss: 0.0001390119723509997 testloss: 0.07689849402909289\n",
      "It: 1300 Loss: 5.948167745373212e-05 testloss: 0.04868501935915639\n",
      "It: 1400 Loss: 3.909064253093675e-05 testloss: 0.051754057748665705\n",
      "It: 1500 Loss: 3.0405379220610484e-05 testloss: 0.053190722515417274\n",
      "It: 1600 Loss: 0.005121855065226555 testloss: 0.1831144810447994\n",
      "It: 1700 Loss: 5.802432133350521e-05 testloss: 0.042483162044645195\n",
      "It: 1800 Loss: 3.4914613934233785e-05 testloss: 0.045757422124214346\n",
      "It: 1900 Loss: 2.5915700462064706e-05 testloss: 0.04738883068352045\n",
      "It: 2000 Loss: 2.3952816263772547e-05 testloss: 0.04877481269926752\n",
      "It: 2100 Loss: 5.225821951171383e-05 testloss: 0.03733596727778742\n",
      "It: 2200 Loss: 2.9664473913726397e-05 testloss: 0.04071975386075751\n",
      "It: 2300 Loss: 2.1345942514017224e-05 testloss: 0.04230007114393603\n",
      "It: 2400 Loss: 1.8013302906183526e-05 testloss: 0.04276502639685151\n",
      "It: 2500 Loss: 6.183433288242668e-05 testloss: 0.02976097852882919\n",
      "It: 2600 Loss: 3.0179413442965597e-05 testloss: 0.03305785542158118\n",
      "It: 2700 Loss: 1.9527091353666037e-05 testloss: 0.034949704050787594\n",
      "It: 2800 Loss: 1.4526595805364195e-05 testloss: 0.0359324457936787\n",
      "It: 2900 Loss: 0.00025114271556958556 testloss: 0.024960139748028982\n",
      "It: 3000 Loss: 3.089328311034478e-05 testloss: 0.028064773213166187\n",
      "It: 3100 Loss: 1.7533327991259284e-05 testloss: 0.03006338185509417\n",
      "It: 3200 Loss: 1.2090868949599098e-05 testloss: 0.031063963059732722\n",
      "It: 3300 Loss: 0.0007965656695887446 testloss: 0.10173059246911584\n",
      "It: 3400 Loss: 2.8525608286145143e-05 testloss: 0.024205792106945276\n",
      "It: 3500 Loss: 1.3935031347500626e-05 testloss: 0.02599087654855778\n",
      "It: 3600 Loss: 8.940117368183564e-06 testloss: 0.02672551460252388\n",
      "It: 3700 Loss: 7.869301043683663e-06 testloss: 0.02767461151470342\n",
      "It: 3800 Loss: 1.8865697711589746e-05 testloss: 0.022620070393807937\n",
      "It: 3900 Loss: 8.5704232333228e-06 testloss: 0.02364482991171767\n",
      "It: 4000 Loss: 5.755761321779573e-06 testloss: 0.023778908824708338\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.9955074246099684e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs3 = NN_H2(3, 100, 4, 1)\n",
    "PINNs3.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs3.parameters()}], lr=1e-3)\n",
    "\n",
    "loss_all_3 = []\n",
    "test_loss_3 = []\n",
    "\n",
    "#########gpu############\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs3.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "#########gpu############\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs3.cuda()\n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs3(bound_x_y_t)\n",
    "    \n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "  \n",
    "    ##### loss f  ######\n",
    "    u_inside = PINNs3(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "\n",
    "    #####loss PI#######\n",
    "    loss = loss_bound+loss_f\n",
    "    pre_H = PINNs3(gan_data_x_t)\n",
    "    \n",
    "    loss_p = k*torch.mean(torch.square(pre_H - gan_data_u))+loss\n",
    "    \n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_3.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss_p.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs3.cpu()\n",
    "    test_loss =  relative_l2(PINNs3(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_3.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item(), 'testloss:', test_loss)\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method4 \n",
    "$\\text { GA - PINN }^{\\dagger}$\n",
    "\n",
    "<div class=\"alert alert-info\">objective functionï¼š\n",
    "\n",
    "$\n",
    "\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:36:59.320951Z",
     "start_time": "2024-03-05T15:34:35.699417Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.15195555984973907 testloss: 0.9482879018388818\n",
      "It: 100 Loss: 0.000955400348175317 testloss: 0.05556256921787538\n",
      "It: 200 Loss: 0.0005944030708633363 testloss: 0.04370431451887307\n",
      "It: 300 Loss: 0.0003739343082997948 testloss: 0.027321512790191013\n",
      "It: 400 Loss: 0.00018563817138783634 testloss: 0.02399408977459166\n",
      "It: 500 Loss: 0.00407264893874526 testloss: 0.071818675881977\n",
      "It: 600 Loss: 0.0002122451551258564 testloss: 0.019486277512777015\n",
      "It: 700 Loss: 0.00010924926755251363 testloss: 0.01840394200398646\n",
      "It: 800 Loss: 5.540635538636707e-05 testloss: 0.017932483227368158\n",
      "It: 900 Loss: 8.373125456273556e-05 testloss: 0.01600349087570247\n",
      "It: 1000 Loss: 1.4849783838144504e-05 testloss: 0.015245551132638618\n",
      "It: 1100 Loss: 1.305284968111664e-05 testloss: 0.013288493630248057\n",
      "It: 1200 Loss: 8.113994226732757e-06 testloss: 0.013125893089820194\n",
      "It: 1300 Loss: 6.977454177103937e-06 testloss: 0.012734309349137827\n",
      "It: 1400 Loss: 0.0008947013411670923 testloss: 0.013229635697125349\n",
      "It: 1500 Loss: 8.198539944714867e-06 testloss: 0.010679574632894073\n",
      "It: 1600 Loss: 6.637514161411673e-06 testloss: 0.010321333774558522\n",
      "It: 1700 Loss: 6.939285867701983e-06 testloss: 0.01043359816455639\n",
      "It: 1800 Loss: 0.0007873335853219032 testloss: 0.01059485440043188\n",
      "It: 1900 Loss: 0.0001723675086395815 testloss: 0.007896054500213072\n",
      "It: 2000 Loss: 0.007235017605125904 testloss: 0.04173503574161541\n",
      "It: 2100 Loss: 0.00010896280582528561 testloss: 0.006336398411818806\n",
      "It: 2200 Loss: 5.9716025134548545e-05 testloss: 0.006191331620031811\n",
      "It: 2300 Loss: 4.004995207651518e-05 testloss: 0.006088338210409034\n",
      "It: 2400 Loss: 0.0012145991204306483 testloss: 0.02299775838539638\n",
      "It: 2500 Loss: 3.9040922274580225e-05 testloss: 0.0049573915994399614\n",
      "It: 2600 Loss: 2.133107955160085e-05 testloss: 0.004831126991969695\n",
      "It: 2700 Loss: 1.2271674677322153e-05 testloss: 0.00464731132970674\n",
      "It: 2800 Loss: 1.677988620940596e-05 testloss: 0.003836511437504178\n",
      "It: 2900 Loss: 5.266368589218473e-06 testloss: 0.003780059075957386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.9967566155828536e-06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs4 = NN_H2(3, 100, 4, 1)\n",
    "PINNs4.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs4.parameters()}], lr=1e-3)\n",
    "\n",
    "discriminator= get_discriminator(4, 100, 1, 1)\n",
    "discriminator.apply(weights_init)\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.01}], lr=5e-3)\n",
    "\n",
    "\n",
    "loss_all_4 = []\n",
    "test_loss_4 = []\n",
    "\n",
    "#########gpu############\n",
    "discriminator.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs4.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "#########gpu############\n",
    "\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs4.cuda()\n",
    "    \n",
    "    ##############loss D############\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    \n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "    ##############loss G############\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    loss_L = torch.mean(torch.square(pre_H - gan_data_u))+torch.mean(1-d_fake)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()  \n",
    "\n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs4(bound_x_y_t)\n",
    "    \n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "  \n",
    "    ##### loss f  ######\n",
    "    \n",
    "    u_inside = PINNs4(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "    \n",
    "    #####loss PI#######\n",
    "    loss = loss_bound+loss_f\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    \n",
    "    loss_p = k*torch.mean(torch.square(pre_H - gan_data_u))+loss\n",
    "    \n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_4.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss_p.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs4.cpu()\n",
    "    test_loss =  relative_l2(PINNs4(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_4.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item(), 'testloss:', test_loss)\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:36:59.326935Z",
     "start_time": "2024-03-05T15:36:59.323092Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss_2 = np.array(test_loss_2)\n",
    "test_loss_3 = np.array(test_loss_3)\n",
    "test_loss_4 = np.array(test_loss_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-05T15:36:59.916413Z",
     "start_time": "2024-03-05T15:36:59.911893Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../experimental_data/J_7/test_loss_2',test_loss_2)\n",
    "np.save('../../experimental_data/J_7/test_loss_3',test_loss_3)\n",
    "np.save('../../experimental_data/J_7/test_loss_4',test_loss_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
