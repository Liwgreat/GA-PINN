{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:26:23.552678Z",
     "start_time": "2024-03-06T03:26:22.311222Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For PINNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:26:23.563368Z",
     "start_time": "2024-03-06T03:26:23.555562Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "N_bound = 100\n",
    "\n",
    "np.random.seed(123)\n",
    "train_x_y_t = lhs(3,N_train)\n",
    "np.random.seed(12345)\n",
    "bound_x_y = lhs(2,N_bound)\n",
    "bound_x_y_t = np.concatenate((bound_x_y,np.zeros((N_bound,1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:26:23.581751Z",
     "start_time": "2024-03-06T03:26:23.566104Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3976],\n",
       "        [0.7691],\n",
       "        [0.9756],\n",
       "        ...,\n",
       "        [0.2023],\n",
       "        [0.6423],\n",
       "        [0.6873]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_y_t = torch.from_numpy(train_x_y_t).float()\n",
    "bound_x_y = torch.from_numpy(bound_x_y).float()\n",
    "bound_x_y_t = torch.from_numpy(bound_x_y_t).float()\n",
    "\n",
    "x = train_x_y_t[:,0:1]\n",
    "y = train_x_y_t[:,1:2]\n",
    "t = train_x_y_t[:,2:3]\n",
    "x.requires_grad_()\n",
    "y.requires_grad_()\n",
    "t.requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:26:23.586189Z",
     "start_time": "2024-03-06T03:26:23.583625Z"
    }
   },
   "outputs": [],
   "source": [
    "def relative_l2(u_pred,u_real):\n",
    "    l2 = np.linalg.norm(u_real-u_pred,2)/np.linalg.norm(u_real,2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:26:23.645828Z",
     "start_time": "2024-03-06T03:26:23.587984Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.integrate\n",
    "from numpy import exp\n",
    "from math import sqrt\n",
    "import math\n",
    "def InIn(x_y_t):\n",
    "    x1 = x_y_t[:,0:1]\n",
    "    x2 = x_y_t[:,1:2]\n",
    "    t = x_y_t[:,2:3]\n",
    "    P = np.zeros_like(t)\n",
    "    for i in range(len(t)):\n",
    "        f = lambda y1,y2 : exp(-((x1[i]-y1)**2+(x2[i]-y2)**2)/(4*t[i]))*(y1-y2)\n",
    "        p,err= scipy.integrate.dblquad(f, -np.inf, np.inf, lambda g : -np.inf, lambda h : np.inf)\n",
    "        P[i] = p/(4*np.pi*t[i])\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:31:30.456277Z",
     "start_time": "2024-03-06T03:26:23.648347Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "test_x_y_t = lhs(3,500)\n",
    "x1 = test_x_y_t[:,0:1]\n",
    "x2 = test_x_y_t[:,1:2]\n",
    "t_ = test_x_y_t[:,2:3]\n",
    "test_u = np.zeros_like(t_)\n",
    "for i in range(len(t_)):\n",
    "    f = lambda y1,y2 : exp(-((x1[i]-y1)**2+(x2[i]-y2)**2)/(4*t_[i]))*(y1-y2)\n",
    "    p,err= scipy.integrate.dblquad(f, -np.inf, np.inf, lambda g : -np.inf, lambda h : np.inf)\n",
    "    test_u[i] = p/(4*np.pi*t_[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:31:30.463980Z",
     "start_time": "2024-03-06T03:31:30.459689Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x_y_t = torch.from_numpy(test_x_y_t).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:31:37.489697Z",
     "start_time": "2024-03-06T03:31:30.466233Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 11\n",
    "np.random.seed(234)\n",
    "gan_data_x_t_a = lhs(3,10)\n",
    "np.random.seed(12345)\n",
    "gan_data_x_t_b = lhs(3,n-10)\n",
    "gan_data_x_t = np.concatenate((gan_data_x_t_a,gan_data_x_t_b),axis=0)\n",
    "gan_data_u = InIn(gan_data_x_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:31:37.497412Z",
     "start_time": "2024-03-06T03:31:37.493825Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_data_x_t = torch.from_numpy(gan_data_x_t).float()\n",
    "gan_data_u = torch.from_numpy(gan_data_u).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method2\n",
    "**$\\text { GA - PINN }$**\n",
    "\n",
    "<div class=\"alert alert-info\">`loss_function：`\n",
    "\n",
    "$\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\mathrm{L}_{\\text {PINN }}:=\\mathrm{L}_f+\\lambda_1 \\mathrm{~L}_b \\text { with } \\mathrm{L}_b:=\\sum_{i=1}^I \\mathrm{~L}_{b_i}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:33:27.546080Z",
     "start_time": "2024-03-06T03:31:37.499829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.1311708688735962\n",
      "It: 100 Loss: 0.0007430515834130347\n",
      "It: 200 Loss: 0.00021597171144094318\n",
      "It: 300 Loss: 0.00023609223717357963\n",
      "It: 400 Loss: 9.096232679439709e-05\n",
      "It: 500 Loss: 0.004289382603019476\n",
      "It: 600 Loss: 0.0001138942243414931\n",
      "It: 700 Loss: 5.9547091950662434e-05\n",
      "It: 800 Loss: 0.00015442213043570518\n",
      "It: 900 Loss: 5.797131234430708e-05\n",
      "It: 1000 Loss: 0.00032865203684195876\n",
      "It: 1100 Loss: 5.259254976408556e-05\n",
      "It: 1200 Loss: 0.00038452137960121036\n",
      "It: 1300 Loss: 4.8821166274137795e-05\n",
      "It: 1400 Loss: 0.0003633820451796055\n",
      "It: 1500 Loss: 4.823055132874288e-05\n",
      "It: 1600 Loss: 2.033650889643468e-05\n",
      "It: 1700 Loss: 3.600789204938337e-05\n",
      "It: 1800 Loss: 0.0003841480065602809\n",
      "It: 1900 Loss: 1.7887703506858088e-05\n",
      "It: 2000 Loss: 0.0001439548359485343\n",
      "It: 2100 Loss: 6.243032203201437e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.947982233716175e-06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs2 = NN_H2(3, 100, 4, 1)\n",
    "PINNs2.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs2.parameters()}], lr=1e-3)\n",
    "\n",
    "discriminator= get_discriminator(4, 100, 1, 1)\n",
    "discriminator.apply(weights_init)\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.01}], lr=5e-3)\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "\n",
    "#########gpu############\n",
    "discriminator.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs2.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "#########gpu############\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs2.cuda()\n",
    "    \n",
    "    ##############loss D############\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    \n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "    ##############loss G ############\n",
    "    pre_H = PINNs2(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    loss_L = torch.mean(torch.square(pre_H - gan_data_u))+torch.mean(1-d_fake)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()  \n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs2(bound_x_y_t)\n",
    "    \n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "    \n",
    "    ##### loss f  ######\n",
    "    u_inside = PINNs2(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "    \n",
    "    loss = loss_bound+loss_f\n",
    "\n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_2.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs2.cpu()\n",
    "    test_loss =  relative_l2(PINNs2(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_2.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method3\n",
    "$\\text { PINN }^{\\dagger}$\n",
    "\n",
    "<div class=\"alert alert-info\">objective function：\n",
    "\n",
    "$\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:33:27.550944Z",
     "start_time": "2024-03-06T03:33:27.548237Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:36:09.779043Z",
     "start_time": "2024-03-06T03:33:27.552818Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.32263725996017456 testloss: 0.776745978600523\n",
      "It: 100 Loss: 0.002004125388339162 testloss: 0.0903167696716681\n",
      "It: 200 Loss: 0.000718765368219465 testloss: 0.06770946252533128\n",
      "It: 300 Loss: 0.0003499066224321723 testloss: 0.04229673322876572\n",
      "It: 400 Loss: 0.00015658096526749432 testloss: 0.03215308792981084\n",
      "It: 500 Loss: 0.00015104970952961594 testloss: 0.025150645315760233\n",
      "It: 600 Loss: 9.652690641814843e-05 testloss: 0.024184145425107977\n",
      "It: 700 Loss: 7.277839176822454e-05 testloss: 0.02377082933467399\n",
      "It: 800 Loss: 5.843529652338475e-05 testloss: 0.02317369549196677\n",
      "It: 900 Loss: 0.0001029540944728069 testloss: 0.019891461661569312\n",
      "It: 1000 Loss: 7.197924423962831e-05 testloss: 0.01907060833515239\n",
      "It: 1100 Loss: 5.455165955936536e-05 testloss: 0.01906435678847533\n",
      "It: 1200 Loss: 4.3407417251728475e-05 testloss: 0.01883144829832424\n",
      "It: 1300 Loss: 9.846669127000496e-05 testloss: 0.07177731887280055\n",
      "It: 1400 Loss: 7.208767055999488e-05 testloss: 0.014887779027812678\n",
      "It: 1500 Loss: 4.9939997552428395e-05 testloss: 0.015170272602830166\n",
      "It: 1600 Loss: 3.728008960024454e-05 testloss: 0.015254543927735882\n",
      "It: 1700 Loss: 2.9033992177573964e-05 testloss: 0.015151154741380119\n",
      "It: 1800 Loss: 0.00013251647760625929 testloss: 0.010957973906536337\n",
      "It: 1900 Loss: 5.5961707403184846e-05 testloss: 0.011776340265520411\n",
      "It: 2000 Loss: 3.7314843211788684e-05 testloss: 0.012064293698823144\n",
      "It: 2100 Loss: 2.6742112822830677e-05 testloss: 0.012171063863444883\n",
      "It: 2200 Loss: 2.0016317648696713e-05 testloss: 0.01213163764684664\n",
      "It: 2300 Loss: 0.00016644850256852806 testloss: 0.013666245447720991\n",
      "It: 2400 Loss: 5.415984196588397e-05 testloss: 0.009114437003228403\n",
      "It: 2500 Loss: 3.2235548133030534e-05 testloss: 0.009320587996594559\n",
      "It: 2600 Loss: 2.1098450815770775e-05 testloss: 0.009432072999678933\n",
      "It: 2700 Loss: 1.4610519428970292e-05 testloss: 0.009427153290634366\n",
      "It: 2800 Loss: 0.00023165291349869221 testloss: 0.058682861087296805\n",
      "It: 2900 Loss: 2.8927399398526177e-05 testloss: 0.008668319593590696\n",
      "It: 3000 Loss: 1.6793539543868974e-05 testloss: 0.008776360224704632\n",
      "It: 3100 Loss: 1.0714025847846642e-05 testloss: 0.00878558430771235\n",
      "It: 3200 Loss: 0.0029998761601746082 testloss: 0.10560465230373244\n",
      "It: 3300 Loss: 2.1791865947307087e-05 testloss: 0.0076670813831597575\n",
      "It: 3400 Loss: 1.0555565495451447e-05 testloss: 0.007659429349139347\n",
      "It: 3500 Loss: 5.94410903431708e-06 testloss: 0.007640172376705276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.997931682737544e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs3 = NN_H2(3, 100, 4, 1)\n",
    "PINNs3.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs3.parameters()}], lr=1e-3)\n",
    "\n",
    "loss_all_3 = []\n",
    "test_loss_3 = []\n",
    "\n",
    "#########gpu############\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs3.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "#########gpu############\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs3.cuda()\n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs3(bound_x_y_t)\n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "  \n",
    "    ##### loss f  ######\n",
    "    u_inside = PINNs3(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "\n",
    "    #####loss PI#######\n",
    "    loss = loss_bound+loss_f\n",
    "    pre_H = PINNs3(gan_data_x_t)\n",
    "    \n",
    "    loss_p = 2*torch.mean(torch.square(pre_H - gan_data_u))+loss\n",
    "    \n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_3.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss_p.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs3.cpu()\n",
    "    test_loss =  relative_l2(PINNs3(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_3.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item(), 'testloss:', test_loss)\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method4 \n",
    "$\\text { GA - PINN }^{\\dagger}$\n",
    "\n",
    "<div class=\"alert alert-info\">objective function：\n",
    "\n",
    "$\n",
    "\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:38:10.389772Z",
     "start_time": "2024-03-06T03:36:09.781590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 0.1311708688735962 testloss: 0.6939685287736654\n",
      "It: 100 Loss: 0.0010731825605034828 testloss: 0.04367262273834801\n",
      "It: 200 Loss: 0.00053010368719697 testloss: 0.030401004854314406\n",
      "It: 300 Loss: 0.0005804613465443254 testloss: 0.019748268080641583\n",
      "It: 400 Loss: 0.00026102690026164055 testloss: 0.017192428978320205\n",
      "It: 500 Loss: 0.00013769525685347617 testloss: 0.015082228793699437\n",
      "It: 600 Loss: 0.0003332324558869004 testloss: 0.016283421496367412\n",
      "It: 700 Loss: 0.00015070817607920617 testloss: 0.011902945741638648\n",
      "It: 800 Loss: 8.756564784562215e-05 testloss: 0.011320813655256872\n",
      "It: 900 Loss: 0.0003164841909892857 testloss: 0.010429091606973482\n",
      "It: 1000 Loss: 0.00011740631452994421 testloss: 0.009873014783275647\n",
      "It: 1100 Loss: 5.711722042178735e-05 testloss: 0.00914985811728192\n",
      "It: 1200 Loss: 7.207490125438198e-05 testloss: 0.008947430630494095\n",
      "It: 1300 Loss: 8.463589438179042e-06 testloss: 0.008190872060609132\n",
      "It: 1400 Loss: 6.736268915119581e-06 testloss: 0.0076950974566190765\n",
      "It: 1500 Loss: 0.006022668443620205 testloss: 0.06242176901362633\n",
      "It: 1600 Loss: 2.2906258891453035e-05 testloss: 0.007286787649510528\n",
      "It: 1700 Loss: 2.3405409592669457e-05 testloss: 0.00596636109947083\n",
      "It: 1800 Loss: 6.488226063083857e-06 testloss: 0.0057553159482980724\n",
      "It: 1900 Loss: 5.854696610185783e-06 testloss: 0.005451510482634329\n",
      "It: 2000 Loss: 5.40251448910567e-06 testloss: 0.005394010837084883\n",
      "It: 2100 Loss: 5.534996944334125e-06 testloss: 0.00534146574672609\n",
      "It: 2200 Loss: 1.01406867543119e-05 testloss: 0.005197490417908835\n",
      "It: 2300 Loss: 5.1959291340608615e-06 testloss: 0.004472822303078599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.983637154509779e-06"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs4 = NN_H2(3, 100, 4, 1)\n",
    "PINNs4.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs4.parameters()}], lr=1e-3)\n",
    "\n",
    "discriminator= get_discriminator(4, 100, 1, 1)\n",
    "discriminator.apply(weights_init)\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.01}], lr=5e-3)\n",
    "\n",
    "loss_all_4 = []\n",
    "test_loss_4 = []\n",
    "\n",
    "#########gpu############\n",
    "discriminator.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "bound_x_y_t = bound_x_y_t.cuda()\n",
    "bound_x_y = bound_x_y.cuda()\n",
    "PINNs4.cuda()\n",
    "x = x.cuda()\n",
    "y = y.cuda()\n",
    "t = t.cuda()\n",
    "#########gpu############\n",
    "\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while  loss1_value>5e-6:\n",
    "    PINNs4.cuda()\n",
    "    \n",
    "    ##############loss D############\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    \n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "    ##############loss G############\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    loss_L = torch.mean(torch.square(pre_H - gan_data_u))+torch.mean(1-d_fake)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()  \n",
    "\n",
    "    ##### loss_Bi  ######\n",
    "    u_bound = PINNs4(bound_x_y_t)\n",
    "    loss_bound = torch.mean(torch.square(u_bound-(bound_x_y[:,0:1]-bound_x_y[:,1:2])))\n",
    "  \n",
    "    ##### loss f  ######\n",
    "    \n",
    "    u_inside = PINNs4(torch.cat((x,y,t),1))\n",
    "    u_x = autograd.grad(outputs=u_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(u_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_y = autograd.grad(outputs=u_inside, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_yy = autograd.grad(outputs=u_y, inputs=y,\n",
    "                              grad_outputs=torch.ones_like(u_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    u_t = autograd.grad(outputs=u_inside, inputs=t,\n",
    "                          grad_outputs=torch.ones_like(u_inside),\n",
    "                          create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    deata_u = u_xx+u_yy\n",
    "    loss_f = torch.mean(torch.square(deata_u-u_t))\n",
    "    \n",
    "    #####loss PI#######\n",
    "    loss = loss_bound+loss_f\n",
    "    pre_H = PINNs4(gan_data_x_t)\n",
    "    \n",
    "    loss_p = k*torch.mean(torch.square(pre_H - gan_data_u))+loss\n",
    "    \n",
    "    loss1_value = loss.item()\n",
    "    \n",
    "    loss_all_4.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss_p.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs4.cpu()\n",
    "    test_loss =  relative_l2(PINNs4(test_x_y_t).detach().numpy(),test_u)\n",
    "    test_loss_4.append(test_loss)\n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item(), 'testloss:', test_loss)\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:38:10.395836Z",
     "start_time": "2024-03-06T03:38:10.392076Z"
    }
   },
   "outputs": [],
   "source": [
    "test_loss_2 = np.array(test_loss_2)\n",
    "test_loss_3 = np.array(test_loss_3)\n",
    "test_loss_4 = np.array(test_loss_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-06T03:38:10.939546Z",
     "start_time": "2024-03-06T03:38:10.935237Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('../../experimental_data/J_11/test_loss_2',test_loss_2)\n",
    "np.save('../../experimental_data/J_11/test_loss_3',test_loss_3)\n",
    "np.save('../../experimental_data/J_11/test_loss_4',test_loss_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
