{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.531658Z",
     "start_time": "2024-02-06T16:13:18.301635Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "%matplotlib inline\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.539603Z",
     "start_time": "2024-02-06T16:13:19.534353Z"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.550645Z",
     "start_time": "2024-02-06T16:13:19.543631Z"
    }
   },
   "outputs": [],
   "source": [
    "class hidden_layers(nn.Module):\n",
    "    def __init__(self,input_number,output_number):\n",
    "        super(hidden_layers, self).__init__()\n",
    "        self.layer = nn.Linear(input_number,output_number)\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.558349Z",
     "start_time": "2024-02-06T16:13:19.553399Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN_H2 (nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        #depth = layers-2\n",
    "        super(NN_H2, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(hidden_layers(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(hidden_layers(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.565960Z",
     "start_time": "2024-02-06T16:13:19.560436Z"
    }
   },
   "outputs": [],
   "source": [
    "class get_discriminator(nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        #depth = layers-2\n",
    "        super(get_discriminator, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(hidden_layers(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(hidden_layers(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "            x = torch.sigmoid(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.593698Z",
     "start_time": "2024-02-06T16:13:19.568056Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 10000\n",
    "N_bound = 500\n",
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "f_data = lhs(10,N_train)\n",
    "np.random.seed(1234)\n",
    "bound_x_all = lhs(10,N_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.602744Z",
     "start_time": "2024-02-06T16:13:19.595918Z"
    }
   },
   "outputs": [],
   "source": [
    "bound_x1 = bound_x_all.copy()\n",
    "bound_x1[:,0:1] = np.zeros((N_bound,1))\n",
    "bound_x2 = bound_x_all.copy()\n",
    "bound_x2[:,1:2] = np.zeros((N_bound,1))\n",
    "bound_x3 = bound_x_all.copy()\n",
    "bound_x3[:,2:3] = np.zeros((N_bound,1))\n",
    "bound_x4 = bound_x_all.copy()\n",
    "bound_x4[:,3:4] = np.zeros((N_bound,1))\n",
    "bound_x5 = bound_x_all.copy()\n",
    "bound_x5[:,4:5] = np.zeros((N_bound,1))\n",
    "bound_x6 = bound_x_all.copy()\n",
    "bound_x6[:,5:6] = np.zeros((N_bound,1))\n",
    "bound_x7 = bound_x_all.copy()\n",
    "bound_x7[:,6:7] = np.zeros((N_bound,1))\n",
    "bound_x8 = bound_x_all.copy()\n",
    "bound_x8[:,7:8] = np.zeros((N_bound,1))\n",
    "bound_x9 = bound_x_all.copy()\n",
    "bound_x9[:,8:9] = np.zeros((N_bound,1))\n",
    "bound_x10 = bound_x_all.copy()\n",
    "bound_x10[:,9:10] = np.zeros((N_bound,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.608164Z",
     "start_time": "2024-02-06T16:13:19.604811Z"
    }
   },
   "outputs": [],
   "source": [
    "bound_x_A = np.concatenate((bound_x1,bound_x2,bound_x3,bound_x4,bound_x5,bound_x6,bound_x7,bound_x8,bound_x9,bound_x10),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.617312Z",
     "start_time": "2024-02-06T16:13:19.610255Z"
    }
   },
   "outputs": [],
   "source": [
    "bound_x1 = bound_x_all.copy()\n",
    "bound_x1[:,0:1] = np.ones((N_bound,1))\n",
    "bound_x2 = bound_x_all.copy()\n",
    "bound_x2[:,1:2] = np.ones((N_bound,1))\n",
    "bound_x3 = bound_x_all.copy()\n",
    "bound_x3[:,2:3] = np.ones((N_bound,1))\n",
    "bound_x4 = bound_x_all.copy()\n",
    "bound_x4[:,3:4] = np.ones((N_bound,1))\n",
    "bound_x5 = bound_x_all.copy()\n",
    "bound_x5[:,4:5] = np.ones((N_bound,1))\n",
    "bound_x6 = bound_x_all.copy()\n",
    "bound_x6[:,5:6] = np.ones((N_bound,1))\n",
    "bound_x7 = bound_x_all.copy()\n",
    "bound_x7[:,6:7] = np.ones((N_bound,1))\n",
    "bound_x8 = bound_x_all.copy()\n",
    "bound_x8[:,7:8] = np.ones((N_bound,1))\n",
    "bound_x9 = bound_x_all.copy()\n",
    "bound_x9[:,8:9] = np.ones((N_bound,1))\n",
    "bound_x10 = bound_x_all.copy()\n",
    "bound_x10[:,9:10] = np.ones((N_bound,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.624410Z",
     "start_time": "2024-02-06T16:13:19.621198Z"
    }
   },
   "outputs": [],
   "source": [
    "bound_x_B = np.concatenate((bound_x1,bound_x2,bound_x3,bound_x4,bound_x5,bound_x6,bound_x7,bound_x8,bound_x9,bound_x10),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.629368Z",
     "start_time": "2024-02-06T16:13:19.626495Z"
    }
   },
   "outputs": [],
   "source": [
    "bound_x = np.concatenate((bound_x_A,bound_x_B),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.635961Z",
     "start_time": "2024-02-06T16:13:19.631303Z"
    }
   },
   "outputs": [],
   "source": [
    "x1= f_data[:,0:1]\n",
    "x2= f_data[:,1:2]\n",
    "x3= f_data[:,2:3]\n",
    "x4= f_data[:,3:4]\n",
    "x5= f_data[:,4:5]\n",
    "x6= f_data[:,5:6]\n",
    "x7= f_data[:,6:7]\n",
    "x8= f_data[:,7:8]\n",
    "x9= f_data[:,8:9]\n",
    "x10= f_data[:,9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.658361Z",
     "start_time": "2024-02-06T16:13:19.638097Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x1 = torch.from_numpy(x1).float()\n",
    "x2 = torch.from_numpy(x2).float()\n",
    "x3 = torch.from_numpy(x3).float()\n",
    "x4 = torch.from_numpy(x4).float()\n",
    "x5 = torch.from_numpy(x5).float()\n",
    "x6 = torch.from_numpy(x6).float()\n",
    "x7 = torch.from_numpy(x7).float()\n",
    "x8 = torch.from_numpy(x8).float()\n",
    "x9 = torch.from_numpy(x9).float()\n",
    "x10 = torch.from_numpy(x10).float()\n",
    "bound_x = torch.from_numpy(bound_x).float()\n",
    "x1.requires_grad_()\n",
    "x2.requires_grad_()\n",
    "x3.requires_grad_()\n",
    "x4.requires_grad_()\n",
    "x5.requires_grad_()\n",
    "x6.requires_grad_()\n",
    "x7.requires_grad_()\n",
    "x8.requires_grad_()\n",
    "x9.requires_grad_()\n",
    "x10.requires_grad_()\n",
    "bound_x.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.663441Z",
     "start_time": "2024-02-06T16:13:19.660607Z"
    }
   },
   "outputs": [],
   "source": [
    "def relative_l2(u_pred,u_real):\n",
    "    l2 = np.linalg.norm(u_real-u_pred,2)/np.linalg.norm(u_real,2)\n",
    "    return l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.688860Z",
     "start_time": "2024-02-06T16:13:19.664973Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "test_data = lhs(10,N_train)\n",
    "test_data_tensor = torch.from_numpy(test_data).float()\n",
    "r = test_data[:,0:1]**2-test_data[:,1:2]**2+test_data[:,2:3]**2-test_data[:,3:4]**2+test_data[:,4:5]*test_data[:,5:6]+test_data[:,6:7]*test_data[:,7:8]*test_data[:,8:9]*test_data[:,9:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:13:19.697326Z",
     "start_time": "2024-02-06T16:13:19.690810Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "gan_data = lhs(10,100)\n",
    "gan_data = torch.from_numpy(gan_data).float()\n",
    "gan_data_u = gan_data[:,0:1]**2-gan_data[:,1:2]**2+gan_data[:,2:3]**2-gan_data[:,3:4]**2+gan_data[:,4:5]*gan_data[:,5:6]+gan_data[:,6:7]*gan_data[:,7:8]*gan_data[:,8:9]*gan_data[:,9:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method3\n",
    "$\\text { PINN }^{\\dagger}$\n",
    "\n",
    "<div class=\"alert alert-info\">`loss_function：`\n",
    "\n",
    "$\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T$\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T16:16:44.550429Z",
     "start_time": "2024-02-06T16:13:19.699377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs3 = NN_H2(10,100,4, 1)\n",
    "PINNs3.apply(weights_init)\n",
    "optimizer1 = optim.Adam(PINNs3.parameters(), lr=0.001)\n",
    "nIter2 = 4000\n",
    "\n",
    "#########gpu#############\n",
    "gan_data = gan_data.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "bound_x = bound_x.cuda()\n",
    "x1 = x1.cuda()\n",
    "x2 = x2.cuda()\n",
    "x3 = x3.cuda()\n",
    "x4 = x4.cuda()\n",
    "x5 = x5.cuda()\n",
    "x6 = x6.cuda()\n",
    "x7 = x7.cuda()\n",
    "x8 = x8.cuda()\n",
    "x9 = x9.cuda()\n",
    "x10 = x10.cuda()\n",
    "#########gpu#############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss_all_3 = []\n",
    "test_loss_3 = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while loss1_value > 0.002 :\n",
    "    PINNs3.cuda()\n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs3(bound_x)\n",
    "    #real_bound = bound_x[:,0:1]*bound_x[:,1:2]+bound_x[:,2:3]*bound_x[:,3:4]+bound_x[:,4:5]*bound_x[:,5:6]+bound_x[:,6:7]*bound_x[:,7:8]+bound_x[:,8:9]*bound_x[:,9:10]\n",
    "    real_bound = bound_x[:,0:1]**2-bound_x[:,1:2]**2+bound_x[:,2:3]**2-bound_x[:,3:4]**2+bound_x[:,4:5]*bound_x[:,5:6]+bound_x[:,6:7]*bound_x[:,7:8]*bound_x[:,8:9]*bound_x[:,9:10]\n",
    "    loss_bound = torch.mean(torch.square(E_bound-real_bound))\n",
    "    ##### loss f  ######\n",
    "    \n",
    "    E = PINNs3(torch.cat((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10),1))\n",
    "    E_x1 = autograd.grad(outputs=E, inputs=x1,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx1 = autograd.grad(outputs=E_x1, inputs=x1,\n",
    "                              grad_outputs=torch.ones_like(E_x1),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_x2 = autograd.grad(outputs=E, inputs=x2,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx2 = autograd.grad(outputs=E_x2, inputs=x2,\n",
    "                              grad_outputs=torch.ones_like(E_x2),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_x3 = autograd.grad(outputs=E, inputs=x3,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx3 = autograd.grad(outputs=E_x3, inputs=x3,\n",
    "                              grad_outputs=torch.ones_like(E_x3),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_x4 = autograd.grad(outputs=E, inputs=x4,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx4 = autograd.grad(outputs=E_x4, inputs=x4,\n",
    "                              grad_outputs=torch.ones_like(E_x4),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_x5 = autograd.grad(outputs=E, inputs=x5,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx5 = autograd.grad(outputs=E_x5, inputs=x5,\n",
    "                              grad_outputs=torch.ones_like(E_x5),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_x6 = autograd.grad(outputs=E, inputs=x6,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx6 = autograd.grad(outputs=E_x6, inputs=x6,\n",
    "                              grad_outputs=torch.ones_like(E_x6),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "    E_x7 = autograd.grad(outputs=E, inputs=x7,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx7 = autograd.grad(outputs=E_x7, inputs=x7,\n",
    "                              grad_outputs=torch.ones_like(E_x7),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "    E_x8 = autograd.grad(outputs=E, inputs=x8,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx8 = autograd.grad(outputs=E_x8, inputs=x8,\n",
    "                              grad_outputs=torch.ones_like(E_x8),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "    E_x9 = autograd.grad(outputs=E, inputs=x9,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx9 = autograd.grad(outputs=E_x9, inputs=x9,\n",
    "                              grad_outputs=torch.ones_like(E_x9),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "    E_x10 = autograd.grad(outputs=E, inputs=x10,\n",
    "                              grad_outputs=torch.ones_like(E),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    E_xx10 = autograd.grad(outputs=E_x10, inputs=x1,\n",
    "                              grad_outputs=torch.ones_like(E_x10),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]       \n",
    "    loss_f = torch.mean(torch.square(E_xx1+E_xx2+E_xx3+E_xx4+E_xx5+E_xx6+E_xx7+E_xx8+E_xx9+E_xx10))\n",
    "    \n",
    "    pre_H = PINNs3(gan_data)\n",
    "    loss_p = loss_bound+loss_f+torch.mean(torch.square(pre_H - gan_data_u)) \n",
    "    loss = loss_bound+loss_f \n",
    "\n",
    "    loss_p = loss_p.cuda()    \n",
    "        \n",
    "    loss1_value = loss.item()\n",
    "    loss_all_3.append(loss1_value)\n",
    "    optimizer1.zero_grad()\n",
    "    loss_p.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs3.cpu()\n",
    "    e1 = relative_l2(PINNs3(test_data_tensor).detach().numpy(),r)\n",
    "    test_loss_3.append(e1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:47:04.014178Z",
     "start_time": "2024-10-28T14:47:04.008889Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/method_3/test_loss_3',test_loss_3)\n",
    "# np.save('../experimental_data/method_3/loss_all_3',loss_all_3)\n",
    "# torch.save(PINNs3,'../saved_model/PINNs3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch and NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:47:04.616666Z",
     "start_time": "2024-10-28T14:47:04.555105Z"
    }
   },
   "outputs": [],
   "source": [
    "Epochs = len(test_loss_3)\n",
    "NRMSE = relative_l2(PINNs3(test_data_tensor).detach().numpy(),r)\n",
    "\n",
    "print('Epochs:',Epochs,'NRMSE:',NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
