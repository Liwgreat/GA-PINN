{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:15.643014Z",
     "start_time": "2024-03-07T04:25:14.559974Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:17.779322Z",
     "start_time": "2024-03-07T04:25:17.757507Z"
    }
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('./NLS.mat')\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "Exact = data['uu']\n",
    "Exact_u = np.real(Exact)\n",
    "Exact_v = np.imag(Exact)\n",
    "Exact_h = np.sqrt(Exact_u**2 + Exact_v**2)\n",
    "\n",
    "X, T = np.meshgrid(x,t)\n",
    "\n",
    "X_star = np.hstack((T.flatten()[:,None], X.flatten()[:,None]))\n",
    "u_star = Exact_u.T.flatten()[:,None]\n",
    "v_star = Exact_v.T.flatten()[:,None]\n",
    "h_star = Exact_h.T.flatten()[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:19.643692Z",
     "start_time": "2024-03-07T04:25:19.613514Z"
    }
   },
   "outputs": [],
   "source": [
    "X_star = torch.from_numpy(X_star).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:20.805298Z",
     "start_time": "2024-03-07T04:25:20.799764Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 20000 \n",
    "N_bound = 100 \n",
    "\n",
    "# idx_x = np.random.choice(x.shape[0], N_bound, replace=False)\n",
    "# x0 = x[idx_x,:]\n",
    "# u0 = Exact_u[idx_x,0:1]\n",
    "# v0 = Exact_v[idx_x,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:22.408140Z",
     "start_time": "2024-03-07T04:25:22.397954Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "index_t = (lhs(1,10))*len(t)\n",
    "index_t = index_t.astype(int).reshape(10,)\n",
    "t_star = t[index_t]\n",
    "index_x = (lhs(1,10))*len(x)\n",
    "index_x = index_x.astype(int).reshape(10,)\n",
    "x_star = x[index_x]\n",
    "t_x_star = np.hstack((t_star, x_star))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:24.025322Z",
     "start_time": "2024-03-07T04:25:24.018302Z"
    }
   },
   "outputs": [],
   "source": [
    "u_star_ = Exact[index_x,index_t]\n",
    "u_star_ = np.hstack((np.real(u_star_).reshape(-1,1), np.imag(u_star_).reshape(-1,1)))\n",
    "n=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:24.992054Z",
     "start_time": "2024-03-07T04:25:24.985654Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_data_x_t = t_x_star\n",
    "gan_data_u = u_star_.reshape(-1,2)\n",
    "gan_data_x_t = torch.from_numpy(gan_data_x_t).float()\n",
    "gan_data_u = torch.from_numpy(gan_data_u).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:25.773866Z",
     "start_time": "2024-03-07T04:25:25.762952Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gan_data_x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:26.493249Z",
     "start_time": "2024-03-07T04:25:26.484250Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_data_u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image With Labeled Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-07T04:25:28.810771Z",
     "start_time": "2024-03-07T04:25:28.487927Z"
    }
   },
   "outputs": [],
   "source": [
    "gan_data_x_t = gan_data_x_t.cpu()\n",
    "lb = np.array([-5.0, 0.0])\n",
    "ub = np.array([5.0, np.pi/2])\n",
    "fig, ax = plt.subplots()\n",
    "gs0 = gridspec.GridSpec(1, 2)\n",
    "gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "ax = plt.subplot(gs0[:, :])\n",
    "ax.plot(gan_data_x_t[:,0:1], gan_data_x_t[:,1:2],  'kx',alpha=1,markersize = 4)\n",
    "ax.set_xlabel('$t$')\n",
    "ax.set_ylabel('$x$')\n",
    "ax.set_title('$|h(t, x)|$', fontsize = 10)\n",
    "h = ax.imshow(Exact_h, interpolation='nearest', cmap='rainbow', \n",
    "              extent=[lb[1], ub[1], lb[0], ub[0]], \n",
    "              origin='lower', aspect='auto')\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(h, cax=cax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.699638Z",
     "start_time": "2024-02-05T14:28:32.695381Z"
    }
   },
   "outputs": [],
   "source": [
    "Exact_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.705639Z",
     "start_time": "2024-02-05T14:28:32.701575Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "index = lhs(1,2000)*len(X_star)\n",
    "index = index.reshape(-1,).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.710340Z",
     "start_time": "2024-02-05T14:28:32.707604Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x = X_star[index]\n",
    "test_u = h_star[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.716967Z",
     "start_time": "2024-02-05T14:28:32.712223Z"
    }
   },
   "outputs": [],
   "source": [
    "test_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data For PINNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.721604Z",
     "start_time": "2024-02-05T14:28:32.718724Z"
    }
   },
   "outputs": [],
   "source": [
    "def sech(x):\n",
    "    h = 2/(np.exp(x)+np.exp(-x))\n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:28:32.744007Z",
     "start_time": "2024-02-05T14:28:32.723518Z"
    }
   },
   "outputs": [],
   "source": [
    "la = np.array([np.pi/2,5])\n",
    "lb = np.array([0,-5])\n",
    "\n",
    "\n",
    "t_limit = np.array([0,np.pi/2])\n",
    "x_limit = np.array([-5,5])\n",
    "\n",
    "np.random.seed(1234)\n",
    "traindata_f = lb+(la-lb)*lhs(2,N_train)\n",
    "\n",
    "traindata_f_t = traindata_f[:,0:1]\n",
    "traindata_f_x = traindata_f[:,1:2]\n",
    "\n",
    "np.random.seed(12345)\n",
    "traindata_x_bound = x_limit[0]+(x_limit[1]-x_limit[0])*lhs(1,N_bound)\n",
    "np.random.seed(123456)\n",
    "traindata_t_bound = t_limit[0]+(t_limit[1]-t_limit[0])*lhs(1,N_bound)\n",
    "\n",
    "data_h_0_x = np.concatenate((np.zeros(traindata_x_bound.shape),traindata_x_bound),axis = 1)\n",
    "\n",
    "data_h_0_x_u = np.concatenate((2*sech(traindata_x_bound),np.zeros(traindata_x_bound.shape)),axis = 1)\n",
    "\n",
    "data_h_t_5 = np.concatenate((traindata_t_bound,np.ones(traindata_t_bound.shape)*(5)),axis = 1)\n",
    "\n",
    "data_h_t_fu_5 = np.concatenate((traindata_t_bound,np.ones(traindata_t_bound.shape)*(-5)),axis = 1)\n",
    "\n",
    "\n",
    "data_5 = np.ones(traindata_t_bound.shape)*(5)\n",
    "\n",
    "data_fu_5 = np.ones(traindata_t_bound.shape)*(-5)\n",
    "\n",
    "traindata_f = torch.from_numpy(traindata_f).float()\n",
    "traindata_f_t = torch.from_numpy(traindata_f_t).float()\n",
    "traindata_f_x = torch.from_numpy(traindata_f_x).float()\n",
    "data_h_0_x = torch.from_numpy(data_h_0_x).float()\n",
    "traindata_t_bound = torch.from_numpy(traindata_t_bound).float()\n",
    "data_5 = torch.from_numpy(data_5).float()\n",
    "data_fu_5 = torch.from_numpy(data_fu_5).float()\n",
    "data_h_t_5 = torch.from_numpy(data_h_t_5).float()\n",
    "data_h_t_fu_5 = torch.from_numpy(data_h_t_fu_5).float()\n",
    "data_h_0_x_u = torch.from_numpy(data_h_0_x_u).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method5 \n",
    "$\\text { GA - PINN* }$\n",
    "<div class=\"alert alert-info\">`loss_function：`<br>\n",
    "`Pre_training：`<br>\n",
    "$\n",
    "\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T\n",
    "$\n",
    "<br>\n",
    "`Follow-up training：`<br>\n",
    "$\n",
    "\\mathrm{L}_D=\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(\\mathbf{x}_T^{(j)}, u_T^{(j)}\\right)\\right]\\right)+D\\left[\\left(x_L^{(j)}, G\\left[x_L^{(j)}\\right]\\right)\\right] \\\\\n",
    "\\mathrm{L}_G=\\mathrm{L}_T+\\frac{1}{J} \\sum_{j=1}^J\\left(1-D\\left[\\left(x_T^{(j)}, G\\left[x_T^{(j)}\\right]\\right)\\right]\\right)\\\\\n",
    "\\overline{\\mathrm{L}}_{\\text {PINN }} =\\mathrm{L}_{\\text {PINN }}+\\lambda_2\\mathrm{L}_T$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:32:40.297592Z",
     "start_time": "2024-02-05T14:28:32.746308Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs5 = NN_H2(2, 100, 4, 2)\n",
    "PINNs5.apply(weights_init)\n",
    "optimizer1 = optim.Adam([{'params': PINNs5.parameters()}], lr=1e-3)\n",
    "nIter2 = 20000\n",
    "\n",
    "discriminator = get_discriminator(4, 100, 3, 1)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "optimizer2 = optim.Adam([{'params': discriminator.parameters(), 'weight_decay': 0.001}], lr=5e-3)\n",
    "\n",
    "\n",
    "\n",
    "traindata_f_t.requires_grad_()\n",
    "traindata_f_x.requires_grad_()\n",
    "data_5.requires_grad_()\n",
    "data_fu_5.requires_grad_()\n",
    "\n",
    "#############gpu##############\n",
    "discriminator = discriminator.cuda()\n",
    "gan_data_x_t = gan_data_x_t.cuda()\n",
    "gan_data_u = gan_data_u.cuda()\n",
    "traindata_t_bound = traindata_t_bound.cuda()\n",
    "traindata_f = traindata_f.cuda()\n",
    "traindata_f_t = traindata_f_t.cuda()\n",
    "traindata_f_x = traindata_f_x.cuda()\n",
    "data_h_0_x = data_h_0_x.cuda()\n",
    "traindata_t_bound = traindata_t_bound.cuda()\n",
    "data_5 = data_5.cuda()\n",
    "data_fu_5 = data_fu_5.cuda()\n",
    "data_h_t_5 = data_h_t_5.cuda()\n",
    "data_h_t_fu_5 = data_h_t_fu_5.cuda()\n",
    "data_h_0_x_u = data_h_0_x_u.cuda()\n",
    "############gpu###############\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss_all_5 = []\n",
    "test_5 = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "while loss1_value > 0.001 and it<3000:\n",
    "    PINNs5 = PINNs5.cuda()\n",
    "    \n",
    "\n",
    "    ##### loss_Bi  ######\n",
    "    pre_H = PINNs5(gan_data_x_t)\n",
    "    \n",
    "    h_0_x = PINNs5(data_h_0_x)\n",
    "    h_t_5 = PINNs5(torch.cat((traindata_t_bound,data_5),1))\n",
    "    h_t_fu_5 = PINNs5(torch.cat((traindata_t_bound,data_fu_5),1))\n",
    "        \n",
    "    loss_h_0_x = torch.mean(torch.square(h_0_x-data_h_0_x_u))\n",
    "    loss_bound_h = torch.mean(torch.square(h_t_fu_5-h_t_5))\n",
    "    grad_h_5 = autograd.grad(outputs=h_t_5, inputs=data_5,\n",
    "                              grad_outputs=torch.ones_like(h_t_5),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    grad_h_fu_5 = autograd.grad(outputs=h_t_fu_5, inputs=data_fu_5,\n",
    "                              grad_outputs=torch.ones_like(h_t_fu_5),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    loss_bound_h_x = torch.mean(torch.square(grad_h_5-grad_h_fu_5))\n",
    "    \n",
    "    ##### loss f  ######\n",
    "    h = PINNs5(torch.cat((traindata_f_t, traindata_f_x), 1))\n",
    "    u = h[:,0:1]\n",
    "    v = h[:,1:2]\n",
    "    u_x = autograd.grad(outputs=u, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_t = autograd.grad(outputs=u, inputs=traindata_f_t,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    v_x = autograd.grad(outputs=v, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    v_xx = autograd.grad(outputs=v_x, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "    v_t = autograd.grad(outputs=v, inputs=traindata_f_t,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "  \n",
    "    f_u = -v_t+0.5*u_xx+(u**2+v**2)*u\n",
    "    f_v = u_t+0.5*v_xx+(u**2+v**2)*v\n",
    "\n",
    "    loss_f = torch.mean(torch.square(f_u))+torch.mean(torch.square(f_v))    \n",
    "    \n",
    "    loss = (loss_h_0_x+loss_bound_h+loss_bound_h_x)*2+loss_f+10*torch.mean(torch.square(pre_H - gan_data_u))    \n",
    "    \n",
    "    loss_p = (loss_h_0_x+loss_bound_h+loss_bound_h_x)*2+loss_f\n",
    "    #######gpu#########\n",
    "    loss = loss.cuda()\n",
    "    \n",
    "    #######gpu#########\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss_all_5.append(loss_p.item())\n",
    "    #loss = loss_f \n",
    "    loss1_value = loss_p.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "        \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs5.cpu()\n",
    "    e1 = relative_l2(np.sqrt(PINNs5(test_x).detach().numpy()[:,0:1]**2 + PINNs5(test_x).detach().numpy()[:,1:2]**2),test_u)\n",
    "    test_5.append(e1)\n",
    "    \n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss_p.item())\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T14:46:15.526722Z",
     "start_time": "2024-02-05T14:32:40.299972Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while loss1_value > 0.001:\n",
    "    PINNs5 = PINNs5.cuda()\n",
    "    \n",
    "    ##########loss D#################\n",
    "    pre_H = PINNs5(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H.detach()),1))\n",
    "    d_real = discriminator(torch.cat((gan_data_x_t,gan_data_u),1))\n",
    "    loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "    \n",
    "    #######gpu#########\n",
    "    loss_d = loss_d.cuda()\n",
    "    \n",
    "    #######gpu#########\n",
    "    \n",
    "    \n",
    "    optimizer2.zero_grad()\n",
    "    loss_d .backward()\n",
    "    optimizer2.step()  \n",
    "    \n",
    "    #########loss G#################\n",
    "    pre_H = PINNs5(gan_data_x_t)\n",
    "    d_fake = discriminator(torch.cat((gan_data_x_t,pre_H),1))\n",
    "        \n",
    "    loss_L = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - gan_data_u))\n",
    "    \n",
    "    #######gpu#########\n",
    "    loss_L = loss_L.cuda()\n",
    "    \n",
    "    #######gpu#########\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss_L.backward()\n",
    "    optimizer1.step()\n",
    "   \n",
    "    ##### loss_Bi  ######\n",
    "    pre_H = PINNs5(gan_data_x_t)\n",
    "    \n",
    "    h_0_x = PINNs5(data_h_0_x)\n",
    "    h_t_5 = PINNs5(torch.cat((traindata_t_bound,data_5),1))\n",
    "    h_t_fu_5 = PINNs5(torch.cat((traindata_t_bound,data_fu_5),1))\n",
    "        \n",
    "    loss_h_0_x = torch.mean(torch.square(h_0_x-data_h_0_x_u))\n",
    "    loss_bound_h = torch.mean(torch.square(h_t_fu_5-h_t_5))\n",
    "    grad_h_5 = autograd.grad(outputs=h_t_5, inputs=data_5,\n",
    "                              grad_outputs=torch.ones_like(h_t_5),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    grad_h_fu_5 = autograd.grad(outputs=h_t_fu_5, inputs=data_fu_5,\n",
    "                              grad_outputs=torch.ones_like(h_t_fu_5),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    \n",
    "    loss_bound_h_x = torch.mean(torch.square(grad_h_5-grad_h_fu_5))\n",
    "    \n",
    "    ##### loss f  ######\n",
    "    h = PINNs5(torch.cat((traindata_f_t, traindata_f_x), 1))\n",
    "    u = h[:,0:1]\n",
    "    v = h[:,1:2]\n",
    "    u_x = autograd.grad(outputs=u, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_xx = autograd.grad(outputs=u_x, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    u_t = autograd.grad(outputs=u, inputs=traindata_f_t,\n",
    "                              grad_outputs=torch.ones_like(u),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    v_x = autograd.grad(outputs=v, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "    v_xx = autograd.grad(outputs=v_x, inputs=traindata_f_x,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "    v_t = autograd.grad(outputs=v, inputs=traindata_f_t,\n",
    "                              grad_outputs=torch.ones_like(v),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]    \n",
    "  \n",
    "    f_u = -v_t+0.5*u_xx+(u**2+v**2)*u\n",
    "    f_v = u_t+0.5*v_xx+(u**2+v**2)*v\n",
    "\n",
    "    loss_f = torch.mean(torch.square(f_u))+torch.mean(torch.square(f_v))    \n",
    "    \n",
    "    loss = (loss_h_0_x+loss_bound_h+loss_bound_h_x)*2+loss_f+10*torch.mean(torch.square(pre_H - gan_data_u))    \n",
    "    \n",
    "    loss_p = (loss_h_0_x+loss_bound_h+loss_bound_h_x)*2+loss_f\n",
    "    #######gpu#########\n",
    "    loss = loss.cuda()\n",
    "    \n",
    "    #######gpu#########\n",
    "    \n",
    "    \n",
    "    \n",
    "    loss_all_5.append(loss_p.item())\n",
    "    #loss = loss_f \n",
    "    loss1_value = loss_p.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    PINNs5.cpu()\n",
    "    e1 = relative_l2(np.sqrt(PINNs5(test_x).detach().numpy()[:,0:1]**2 + PINNs5(test_x).detach().numpy()[:,1:2]**2),test_u)\n",
    "    test_5.append(e1)\n",
    "    \n",
    "    \n",
    "    if it % 100 == 0:\n",
    "        print('It:', it, 'Loss:', loss_p.item())\n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:54:32.483260Z",
     "start_time": "2024-10-28T14:54:32.478256Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/method_5/test_loss_5',test_5)\n",
    "# np.save('../experimental_data/method_5/loss_all_5',loss_all_5)\n",
    "# torch.save(PINNs5,'../saved_model/PINNs5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epoch and NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T14:54:32.816992Z",
     "start_time": "2024-10-28T14:54:32.755558Z"
    }
   },
   "outputs": [],
   "source": [
    "Epochs = len(test_5)\n",
    "NRMSE = relative_l2(np.sqrt(PINNs5(test_x).detach().numpy()[:,0:1]**2 + PINNs5(test_x).detach().numpy()[:,1:2]**2),test_u)\n",
    "\n",
    "print('Epochs:',Epochs,'NRMSE:',NRMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GA-PINNs",
   "language": "python",
   "name": "gapings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
