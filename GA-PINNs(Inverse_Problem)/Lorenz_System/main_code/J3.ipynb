{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b2bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_traindata():\n",
    "    data = np.load(\"./Lorenz.npz\")\n",
    "    return data[\"t\"], data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19c18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92554f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t,train_data = gen_traindata()\n",
    "\n",
    "train_t = torch.from_numpy(train_t).float()\n",
    "train_data = torch.from_numpy(train_data).float()\n",
    "\n",
    "n=6\n",
    "np.random.seed(5678)\n",
    "index_a = np.random.choice(np.arange(25,dtype=int),n,replace=False)\n",
    "train_t = train_t[index_a]\n",
    "train_data = train_data[index_a]\n",
    "\n",
    "train_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "train_t = train_t.cuda()\n",
    "train_data = train_data.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f36c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3a363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = torch.tensor(1.0, requires_grad=True)\n",
    "C2 = torch.tensor(1.0, requires_grad=True)\n",
    "C3 = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea63c0d",
   "metadata": {},
   "source": [
    "## PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bf68c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1325.8997802734375\n",
      "C1: tensor(0.9990, requires_grad=True) C2: tensor(0.9990, requires_grad=True) C3: tensor(0.9990, requires_grad=True)\n",
      "It: 999 Loss: 158.54417419433594\n",
      "C1: tensor(0.2212, requires_grad=True) C2: tensor(1.4431, requires_grad=True) C3: tensor(0.2973, requires_grad=True)\n",
      "It: 1999 Loss: 133.23974609375\n",
      "C1: tensor(0.4648, requires_grad=True) C2: tensor(2.6030, requires_grad=True) C3: tensor(0.1605, requires_grad=True)\n",
      "It: 2999 Loss: 123.96554565429688\n",
      "C1: tensor(0.6235, requires_grad=True) C2: tensor(3.8289, requires_grad=True) C3: tensor(0.1341, requires_grad=True)\n",
      "It: 3999 Loss: 117.2294921875\n",
      "C1: tensor(0.7819, requires_grad=True) C2: tensor(5.0305, requires_grad=True) C3: tensor(0.0995, requires_grad=True)\n",
      "It: 4999 Loss: 111.18192291259766\n",
      "C1: tensor(0.9031, requires_grad=True) C2: tensor(6.2086, requires_grad=True) C3: tensor(0.1007, requires_grad=True)\n",
      "It: 5999 Loss: 105.47624206542969\n",
      "C1: tensor(1.0358, requires_grad=True) C2: tensor(7.3647, requires_grad=True) C3: tensor(0.1036, requires_grad=True)\n",
      "It: 6999 Loss: 100.20332336425781\n",
      "C1: tensor(1.1361, requires_grad=True) C2: tensor(8.4964, requires_grad=True) C3: tensor(0.1197, requires_grad=True)\n",
      "It: 7999 Loss: 94.1108169555664\n",
      "C1: tensor(1.2530, requires_grad=True) C2: tensor(9.6185, requires_grad=True) C3: tensor(0.1551, requires_grad=True)\n",
      "It: 8999 Loss: 45.76681900024414\n",
      "C1: tensor(1.8570, requires_grad=True) C2: tensor(11.0191, requires_grad=True) C3: tensor(1.3879, requires_grad=True)\n",
      "It: 9999 Loss: 20.75109100341797\n",
      "C1: tensor(3.2879, requires_grad=True) C2: tensor(12.1131, requires_grad=True) C3: tensor(2.2793, requires_grad=True)\n",
      "It: 10999 Loss: 10.413108825683594\n",
      "C1: tensor(4.9237, requires_grad=True) C2: tensor(12.8911, requires_grad=True) C3: tensor(2.7139, requires_grad=True)\n",
      "It: 11999 Loss: 5.131772518157959\n",
      "C1: tensor(6.1643, requires_grad=True) C2: tensor(13.5133, requires_grad=True) C3: tensor(2.8401, requires_grad=True)\n",
      "It: 12999 Loss: 2.44126296043396\n",
      "C1: tensor(7.0695, requires_grad=True) C2: tensor(14.0388, requires_grad=True) C3: tensor(2.8046, requires_grad=True)\n",
      "It: 13999 Loss: 1.0900053977966309\n",
      "C1: tensor(7.8155, requires_grad=True) C2: tensor(14.4504, requires_grad=True) C3: tensor(2.7459, requires_grad=True)\n",
      "It: 14999 Loss: 0.47077712416648865\n",
      "C1: tensor(8.4642, requires_grad=True) C2: tensor(14.7171, requires_grad=True) C3: tensor(2.7064, requires_grad=True)\n",
      "It: 15999 Loss: 0.28360235691070557\n",
      "C1: tensor(9.0119, requires_grad=True) C2: tensor(14.8549, requires_grad=True) C3: tensor(2.6879, requires_grad=True)\n",
      "It: 16999 Loss: 0.1050807386636734\n",
      "C1: tensor(9.4391, requires_grad=True) C2: tensor(14.9238, requires_grad=True) C3: tensor(2.6787, requires_grad=True)\n",
      "It: 17999 Loss: 0.03255379945039749\n",
      "C1: tensor(9.7328, requires_grad=True) C2: tensor(14.9626, requires_grad=True) C3: tensor(2.6728, requires_grad=True)\n",
      "It: 18999 Loss: 0.017945315688848495\n",
      "C1: tensor(9.8963, requires_grad=True) C2: tensor(14.9836, requires_grad=True) C3: tensor(2.6695, requires_grad=True)\n",
      "It: 19999 Loss: 0.012331778183579445\n",
      "C1: tensor(9.9641, requires_grad=True) C2: tensor(14.9928, requires_grad=True) C3: tensor(2.6681, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012331778183579445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs1 = NN_H2(1, 40, 2, 3)\n",
    "PINNs1.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1,C2,C3], 'lr': 0.001})\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_1 = []\n",
    "test_loss_1 = []\n",
    "C1_a_list = []\n",
    "C2_a_list = []\n",
    "C3_a_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<20000:\n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs1(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs1(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs1(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_1.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        \n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_a_list.append(C1.detach().item())\n",
    "        C2_a_list.append(C2.detach().item())\n",
    "        C3_a_list.append(C3.detach().item())\n",
    "        print('C1:',C1,'C2:',C2,'C3:',C3)\n",
    "         \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c8ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3acc54f8",
   "metadata": {},
   "source": [
    "## GA-PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aab9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadf4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_b = torch.tensor(1.0, requires_grad=True)\n",
    "C2_b = torch.tensor(1.0, requires_grad=True)\n",
    "C3_b = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199f787a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1305.174560546875\n",
      "C1: tensor(0.9990, requires_grad=True) C2: tensor(0.9990, requires_grad=True) C3: tensor(0.9990, requires_grad=True)\n",
      "It: 999 Loss: 142.97412109375\n",
      "C1: tensor(0.3297, requires_grad=True) C2: tensor(1.7282, requires_grad=True) C3: tensor(0.2111, requires_grad=True)\n",
      "It: 1999 Loss: 127.29408264160156\n",
      "C1: tensor(0.6482, requires_grad=True) C2: tensor(3.0684, requires_grad=True) C3: tensor(0.1186, requires_grad=True)\n",
      "It: 2999 Loss: 120.51895141601562\n",
      "C1: tensor(0.7657, requires_grad=True) C2: tensor(4.3173, requires_grad=True) C3: tensor(0.1070, requires_grad=True)\n",
      "It: 3999 Loss: 113.29388427734375\n",
      "C1: tensor(0.8922, requires_grad=True) C2: tensor(5.5035, requires_grad=True) C3: tensor(0.0990, requires_grad=True)\n",
      "It: 4999 Loss: 108.39942932128906\n",
      "C1: tensor(0.9877, requires_grad=True) C2: tensor(6.6664, requires_grad=True) C3: tensor(0.1002, requires_grad=True)\n",
      "It: 5999 Loss: 103.38323974609375\n",
      "C1: tensor(1.0733, requires_grad=True) C2: tensor(7.8072, requires_grad=True) C3: tensor(0.1077, requires_grad=True)\n",
      "It: 6999 Loss: 97.75920104980469\n",
      "C1: tensor(1.1780, requires_grad=True) C2: tensor(8.9355, requires_grad=True) C3: tensor(0.1297, requires_grad=True)\n",
      "It: 7999 Loss: 91.39395141601562\n",
      "C1: tensor(1.3069, requires_grad=True) C2: tensor(10.0641, requires_grad=True) C3: tensor(0.1896, requires_grad=True)\n",
      "It: 8999 Loss: 31.717670440673828\n",
      "C1: tensor(2.4391, requires_grad=True) C2: tensor(11.5112, requires_grad=True) C3: tensor(1.8600, requires_grad=True)\n",
      "It: 9999 Loss: 15.515279769897461\n",
      "C1: tensor(4.0707, requires_grad=True) C2: tensor(12.4393, requires_grad=True) C3: tensor(2.5207, requires_grad=True)\n",
      "It: 10999 Loss: 7.604382514953613\n",
      "C1: tensor(5.6046, requires_grad=True) C2: tensor(13.1432, requires_grad=True) C3: tensor(2.8192, requires_grad=True)\n",
      "It: 11999 Loss: 3.740669012069702\n",
      "C1: tensor(6.6429, requires_grad=True) C2: tensor(13.7278, requires_grad=True) C3: tensor(2.8430, requires_grad=True)\n",
      "It: 12999 Loss: 1.7053114175796509\n",
      "C1: tensor(7.4533, requires_grad=True) C2: tensor(14.2184, requires_grad=True) C3: tensor(2.7829, requires_grad=True)\n",
      "It: 13999 Loss: 0.7267559766769409\n",
      "C1: tensor(8.1486, requires_grad=True) C2: tensor(14.5800, requires_grad=True) C3: tensor(2.7295, requires_grad=True)\n",
      "It: 14999 Loss: 0.3017120361328125\n",
      "C1: tensor(8.7519, requires_grad=True) C2: tensor(14.7929, requires_grad=True) C3: tensor(2.6980, requires_grad=True)\n",
      "It: 15999 Loss: 0.13588179647922516\n",
      "C1: tensor(9.2478, requires_grad=True) C2: tensor(14.8960, requires_grad=True) C3: tensor(2.6835, requires_grad=True)\n",
      "It: 16999 Loss: 0.043628618121147156\n",
      "C1: tensor(9.6120, requires_grad=True) C2: tensor(14.9489, requires_grad=True) C3: tensor(2.6756, requires_grad=True)\n",
      "It: 17999 Loss: 0.018227800726890564\n",
      "C1: tensor(9.8389, requires_grad=True) C2: tensor(14.9775, requires_grad=True) C3: tensor(2.6709, requires_grad=True)\n",
      "It: 18999 Loss: 0.011525464244186878\n",
      "C1: tensor(9.9477, requires_grad=True) C2: tensor(14.9914, requires_grad=True) C3: tensor(2.6685, requires_grad=True)\n",
      "It: 19999 Loss: 0.008427070453763008\n",
      "C1: tensor(9.9857, requires_grad=True) C2: tensor(14.9964, requires_grad=True) C3: tensor(2.6676, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008427070453763008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs2 = NN_H2(1, 40, 2, 3)\n",
    "PINNs2.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs2.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1_b,C2_b,C3_b], 'lr': 0.001})\n",
    "\n",
    "discriminator = get_discriminator(4, 40, 2, 1)\n",
    "discriminator.cuda()\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in discriminator.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "        \n",
    "optimizer2 = optim.Adam(discriminator.parameters(), lr=5e-3,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "C1_b_list = []\n",
    "C2_b_list = []\n",
    "C3_b_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<20000:\n",
    "    \n",
    "    if it <=1000:    \n",
    "    \n",
    "        ############ loss D ###########\n",
    "        pre_H = PINNs2(train_t)\n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H.detach()),1))\n",
    "        d_real = discriminator(torch.cat((train_t,train_data),1))\n",
    "\n",
    "        loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer2.step()  \n",
    "\n",
    "        ####### loss G#######\n",
    "        pre_H = PINNs2(train_t)  \n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H),1))\n",
    "\n",
    "        loss_L = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - train_data))\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss_L.backward()\n",
    "        optimizer1.step()     \n",
    "    \n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs2(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs2(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1_b*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2_b-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3_b*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs2(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_2.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        \n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_b_list.append(C1_b.detach().item())\n",
    "        C2_b_list.append(C2_b.detach().item())\n",
    "        C3_b_list.append(C3_b.detach().item())\n",
    "        print('C1:',C1_b,'C2:',C2_b,'C3:',C3_b)\n",
    "        \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c999fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5526647e",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b2655",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5ecd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/J3/C1_a_list',C1_a_list)\n",
    "# np.save('../experimental_data/J3/C1_b_list',C1_b_list)\n",
    "# np.save('../experimental_data/J3/C2_a_list',C2_a_list)\n",
    "# np.save('../experimental_data/J3/C2_b_list',C2_b_list)\n",
    "# np.save('../experimental_data/J3/C3_a_list',C3_a_list)\n",
    "# np.save('../experimental_data/J3/C3_b_list',C3_b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515a5d91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd64c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
