{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b2bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_traindata():\n",
    "    data = np.load(\"./Lorenz.npz\")\n",
    "    return data[\"t\"], data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19c18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92554f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t,train_data = gen_traindata()\n",
    "\n",
    "train_t = torch.from_numpy(train_t).float()\n",
    "train_data = torch.from_numpy(train_data).float()\n",
    "\n",
    "n=12\n",
    "np.random.seed(5678)\n",
    "index_a = np.random.choice(np.arange(25,dtype=int),n,replace=False)\n",
    "train_t = train_t[index_a]\n",
    "train_data = train_data[index_a]\n",
    "\n",
    "train_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "train_t = train_t.cuda()\n",
    "train_data = train_data.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f36c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3a363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = torch.tensor(1.0, requires_grad=True)\n",
    "C2 = torch.tensor(1.0, requires_grad=True)\n",
    "C3 = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea63c0d",
   "metadata": {},
   "source": [
    "## $\\text{PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bf68c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1519.5653076171875\n",
      "C1: tensor(0.9990, requires_grad=True) C2: tensor(0.9990, requires_grad=True) C3: tensor(0.9990, requires_grad=True)\n",
      "It: 999 Loss: 149.2056427001953\n",
      "C1: tensor(0.2343, requires_grad=True) C2: tensor(1.6374, requires_grad=True) C3: tensor(0.2917, requires_grad=True)\n",
      "It: 1999 Loss: 120.7764663696289\n",
      "C1: tensor(0.4264, requires_grad=True) C2: tensor(2.8392, requires_grad=True) C3: tensor(0.1284, requires_grad=True)\n",
      "It: 2999 Loss: 110.8579330444336\n",
      "C1: tensor(0.5491, requires_grad=True) C2: tensor(4.0375, requires_grad=True) C3: tensor(0.0733, requires_grad=True)\n",
      "It: 3999 Loss: 105.59813690185547\n",
      "C1: tensor(0.6631, requires_grad=True) C2: tensor(5.1905, requires_grad=True) C3: tensor(0.0614, requires_grad=True)\n",
      "It: 4999 Loss: 100.8341293334961\n",
      "C1: tensor(0.7422, requires_grad=True) C2: tensor(6.3110, requires_grad=True) C3: tensor(0.0555, requires_grad=True)\n",
      "It: 5999 Loss: 96.95332336425781\n",
      "C1: tensor(0.8161, requires_grad=True) C2: tensor(7.4144, requires_grad=True) C3: tensor(0.0663, requires_grad=True)\n",
      "It: 6999 Loss: 93.14995574951172\n",
      "C1: tensor(0.9049, requires_grad=True) C2: tensor(8.5088, requires_grad=True) C3: tensor(0.0884, requires_grad=True)\n",
      "It: 7999 Loss: 88.88713073730469\n",
      "C1: tensor(1.0040, requires_grad=True) C2: tensor(9.6272, requires_grad=True) C3: tensor(0.1366, requires_grad=True)\n",
      "It: 8999 Loss: 41.112369537353516\n",
      "C1: tensor(1.7682, requires_grad=True) C2: tensor(11.1998, requires_grad=True) C3: tensor(1.4997, requires_grad=True)\n",
      "It: 9999 Loss: 20.496280670166016\n",
      "C1: tensor(2.8774, requires_grad=True) C2: tensor(12.2893, requires_grad=True) C3: tensor(2.3213, requires_grad=True)\n",
      "It: 10999 Loss: 10.453742980957031\n",
      "C1: tensor(4.6174, requires_grad=True) C2: tensor(13.0847, requires_grad=True) C3: tensor(2.7726, requires_grad=True)\n",
      "It: 11999 Loss: 5.158703327178955\n",
      "C1: tensor(5.9177, requires_grad=True) C2: tensor(13.6981, requires_grad=True) C3: tensor(2.8826, requires_grad=True)\n",
      "It: 12999 Loss: 2.507113456726074\n",
      "C1: tensor(6.8473, requires_grad=True) C2: tensor(14.1936, requires_grad=True) C3: tensor(2.8241, requires_grad=True)\n",
      "It: 13999 Loss: 1.1546730995178223\n",
      "C1: tensor(7.6111, requires_grad=True) C2: tensor(14.5659, requires_grad=True) C3: tensor(2.7547, requires_grad=True)\n",
      "It: 14999 Loss: 0.5275404453277588\n",
      "C1: tensor(8.2678, requires_grad=True) C2: tensor(14.7901, requires_grad=True) C3: tensor(2.7120, requires_grad=True)\n",
      "It: 15999 Loss: 0.2379586547613144\n",
      "C1: tensor(8.8274, requires_grad=True) C2: tensor(14.8936, requires_grad=True) C3: tensor(2.6925, requires_grad=True)\n",
      "It: 16999 Loss: 0.1006428599357605\n",
      "C1: tensor(9.2800, requires_grad=True) C2: tensor(14.9420, requires_grad=True) C3: tensor(2.6827, requires_grad=True)\n",
      "It: 17999 Loss: 0.12221171706914902\n",
      "C1: tensor(9.6132, requires_grad=True) C2: tensor(14.9709, requires_grad=True) C3: tensor(2.6756, requires_grad=True)\n",
      "It: 18999 Loss: 0.027270885184407234\n",
      "C1: tensor(9.8221, requires_grad=True) C2: tensor(14.9878, requires_grad=True) C3: tensor(2.6714, requires_grad=True)\n",
      "It: 19999 Loss: 0.02172194980084896\n",
      "C1: tensor(9.9242, requires_grad=True) C2: tensor(14.9958, requires_grad=True) C3: tensor(2.6689, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.02172194980084896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs1 = NN_H2(1, 40, 2, 3)\n",
    "PINNs1.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1,C2,C3], 'lr': 0.001})\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_1 = []\n",
    "test_loss_1 = []\n",
    "C1_a_list = []\n",
    "C2_a_list = []\n",
    "C3_a_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<20000:\n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs1(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs1(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs1(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_1.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "\n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_a_list.append(C1.detach().item())\n",
    "        C2_a_list.append(C2.detach().item())\n",
    "        C3_a_list.append(C3.detach().item())\n",
    "        print('C1:',C1,'C2:',C2,'C3:',C3)\n",
    "        \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c8ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3acc54f8",
   "metadata": {},
   "source": [
    "## $\\text{GA-PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aab9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadf4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1_b = torch.tensor(1.0, requires_grad=True)\n",
    "C2_b = torch.tensor(1.0, requires_grad=True)\n",
    "C3_b = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199f787a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1496.553955078125\n",
      "C1: tensor(0.9990, requires_grad=True) C2: tensor(0.9990, requires_grad=True) C3: tensor(0.9990, requires_grad=True)\n",
      "It: 999 Loss: 135.3621368408203\n",
      "C1: tensor(0.3058, requires_grad=True) C2: tensor(1.8796, requires_grad=True) C3: tensor(0.2083, requires_grad=True)\n",
      "It: 1999 Loss: 116.08294677734375\n",
      "C1: tensor(0.4915, requires_grad=True) C2: tensor(3.1844, requires_grad=True) C3: tensor(0.1033, requires_grad=True)\n",
      "It: 2999 Loss: 107.44810485839844\n",
      "C1: tensor(0.6228, requires_grad=True) C2: tensor(4.4844, requires_grad=True) C3: tensor(0.0641, requires_grad=True)\n",
      "It: 3999 Loss: 102.51361083984375\n",
      "C1: tensor(0.7163, requires_grad=True) C2: tensor(5.6723, requires_grad=True) C3: tensor(0.0540, requires_grad=True)\n",
      "It: 4999 Loss: 98.89891052246094\n",
      "C1: tensor(0.7852, requires_grad=True) C2: tensor(6.7985, requires_grad=True) C3: tensor(0.0590, requires_grad=True)\n",
      "It: 5999 Loss: 95.25296020507812\n",
      "C1: tensor(0.8573, requires_grad=True) C2: tensor(7.8961, requires_grad=True) C3: tensor(0.0745, requires_grad=True)\n",
      "It: 6999 Loss: 91.40213012695312\n",
      "C1: tensor(0.9455, requires_grad=True) C2: tensor(8.9920, requires_grad=True) C3: tensor(0.1043, requires_grad=True)\n",
      "It: 7999 Loss: 85.15974426269531\n",
      "C1: tensor(1.1068, requires_grad=True) C2: tensor(10.1753, requires_grad=True) C3: tensor(0.3099, requires_grad=True)\n",
      "It: 8999 Loss: 29.108247756958008\n",
      "C1: tensor(2.2378, requires_grad=True) C2: tensor(11.7310, requires_grad=True) C3: tensor(1.9608, requires_grad=True)\n",
      "It: 9999 Loss: 15.251752853393555\n",
      "C1: tensor(3.7458, requires_grad=True) C2: tensor(12.6567, requires_grad=True) C3: tensor(2.5891, requires_grad=True)\n",
      "It: 10999 Loss: 7.494001865386963\n",
      "C1: tensor(5.3918, requires_grad=True) C2: tensor(13.3623, requires_grad=True) C3: tensor(2.8787, requires_grad=True)\n",
      "It: 11999 Loss: 3.5550124645233154\n",
      "C1: tensor(6.4794, requires_grad=True) C2: tensor(13.9222, requires_grad=True) C3: tensor(2.8744, requires_grad=True)\n",
      "It: 12999 Loss: 1.6269006729125977\n",
      "C1: tensor(7.3106, requires_grad=True) C2: tensor(14.3734, requires_grad=True) C3: tensor(2.7964, requires_grad=True)\n",
      "It: 13999 Loss: 0.7259169816970825\n",
      "C1: tensor(8.0134, requires_grad=True) C2: tensor(14.6865, requires_grad=True) C3: tensor(2.7342, requires_grad=True)\n",
      "It: 14999 Loss: 0.3151957392692566\n",
      "C1: tensor(8.6205, requires_grad=True) C2: tensor(14.8529, requires_grad=True) C3: tensor(2.7016, requires_grad=True)\n",
      "It: 15999 Loss: 0.1263195127248764\n",
      "C1: tensor(9.1245, requires_grad=True) C2: tensor(14.9251, requires_grad=True) C3: tensor(2.6874, requires_grad=True)\n",
      "It: 16999 Loss: 0.04773811250925064\n",
      "C1: tensor(9.5108, requires_grad=True) C2: tensor(14.9620, requires_grad=True) C3: tensor(2.6790, requires_grad=True)\n",
      "It: 17999 Loss: 0.01738811284303665\n",
      "C1: tensor(9.7692, requires_grad=True) C2: tensor(14.9835, requires_grad=True) C3: tensor(2.6730, requires_grad=True)\n",
      "It: 18999 Loss: 0.013842328451573849\n",
      "C1: tensor(9.9096, requires_grad=True) C2: tensor(14.9944, requires_grad=True) C3: tensor(2.6697, requires_grad=True)\n",
      "It: 19999 Loss: 0.015863755717873573\n",
      "C1: tensor(9.9678, requires_grad=True) C2: tensor(14.9988, requires_grad=True) C3: tensor(2.6683, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015863755717873573"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs2 = NN_H2(1, 40, 2, 3)\n",
    "PINNs2.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs2.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1_b,C2_b,C3_b], 'lr': 0.001})\n",
    "\n",
    "discriminator = get_discriminator(4, 40, 2, 1)\n",
    "discriminator.cuda()\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in discriminator.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "        \n",
    "optimizer2 = optim.Adam(discriminator.parameters(), lr=5e-3,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "C1_b_list = []\n",
    "C2_b_list = []\n",
    "C3_b_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "\n",
    "while  it<20000:\n",
    "    \n",
    "    if it <=1000:    \n",
    "    \n",
    "        ############ loss D ###########\n",
    "        pre_H = PINNs2(train_t)\n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H.detach()),1))\n",
    "        d_real = discriminator(torch.cat((train_t,train_data),1))\n",
    "\n",
    "        loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer2.step()  \n",
    "\n",
    "        ####### loss G#######\n",
    "        pre_H = PINNs2(train_t)  \n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H),1))\n",
    "\n",
    "        loss_L = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - train_data))\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss_L.backward()\n",
    "        optimizer1.step()     \n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs2(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs2(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1_b*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2_b-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3_b*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs2(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_2.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "\n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_b_list.append(C1_b.detach().item())\n",
    "        C2_b_list.append(C2_b.detach().item())\n",
    "        C3_b_list.append(C3_b.detach().item())\n",
    "        print('C1:',C1_b,'C2:',C2_b,'C3:',C3_b)\n",
    "        \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c999fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ca5cd8d",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5922e9d8",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba286ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:27:32.291265Z",
     "start_time": "2024-10-28T11:27:32.285907Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/J2/C1_a_list',C1_a_list)\n",
    "# np.save('../experimental_data/J2/C1_b_list',C1_b_list)\n",
    "# np.save('../experimental_data/J2/C2_a_list',C2_a_list)\n",
    "# np.save('../experimental_data/J2/C2_b_list',C2_b_list)\n",
    "# np.save('../experimental_data/J2/C3_a_list',C3_a_list)\n",
    "# np.save('../experimental_data/J2/C3_b_list',C3_b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531d89fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
