{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b2bf36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:36.037442Z",
     "start_time": "2024-02-11T09:40:34.757896Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd025d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:36.046980Z",
     "start_time": "2024-02-11T09:40:36.041190Z"
    }
   },
   "outputs": [],
   "source": [
    "def gen_traindata():\n",
    "    data = np.load(\"./Lorenz.npz\")\n",
    "    return data[\"t\"], data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19c18ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:39.836349Z",
     "start_time": "2024-02-11T09:40:36.050327Z"
    }
   },
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92554f1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:39.847826Z",
     "start_time": "2024-02-11T09:40:39.839376Z"
    }
   },
   "outputs": [],
   "source": [
    "train_t,train_data = gen_traindata()\n",
    "\n",
    "train_t = torch.from_numpy(train_t).float()\n",
    "train_data = torch.from_numpy(train_data).float()\n",
    "\n",
    "train_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "train_t = train_t.cuda()\n",
    "train_data = train_data.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14f36c06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:39.856956Z",
     "start_time": "2024-02-11T09:40:39.850531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([25, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f3a363d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:40:39.863929Z",
     "start_time": "2024-02-11T09:40:39.859513Z"
    }
   },
   "outputs": [],
   "source": [
    "C1 = torch.tensor(1.0, requires_grad=True)\n",
    "C2 = torch.tensor(1.0, requires_grad=True)\n",
    "C3 = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea63c0d",
   "metadata": {},
   "source": [
    "## $\\text{PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bf68c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:44:25.918720Z",
     "start_time": "2024-02-11T09:40:39.866920Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1448.243408203125\n",
      "C1: tensor(0.9990, requires_grad=True) C2: tensor(0.9990, requires_grad=True) C3: tensor(0.9990, requires_grad=True)\n",
      "It: 999 Loss: 144.68203735351562\n",
      "C1: tensor(0.2103, requires_grad=True) C2: tensor(1.4801, requires_grad=True) C3: tensor(0.2945, requires_grad=True)\n",
      "It: 1999 Loss: 133.59182739257812\n",
      "C1: tensor(0.3169, requires_grad=True) C2: tensor(2.5048, requires_grad=True) C3: tensor(0.1813, requires_grad=True)\n",
      "It: 2999 Loss: 130.49435424804688\n",
      "C1: tensor(0.3759, requires_grad=True) C2: tensor(3.6754, requires_grad=True) C3: tensor(0.1611, requires_grad=True)\n",
      "It: 3999 Loss: 127.93805694580078\n",
      "C1: tensor(0.4165, requires_grad=True) C2: tensor(4.8596, requires_grad=True) C3: tensor(0.1491, requires_grad=True)\n",
      "It: 4999 Loss: 125.52500915527344\n",
      "C1: tensor(0.4519, requires_grad=True) C2: tensor(6.0252, requires_grad=True) C3: tensor(0.1431, requires_grad=True)\n",
      "It: 5999 Loss: 122.81959533691406\n",
      "C1: tensor(0.4946, requires_grad=True) C2: tensor(7.1952, requires_grad=True) C3: tensor(0.1497, requires_grad=True)\n",
      "It: 6999 Loss: 119.19924926757812\n",
      "C1: tensor(0.5684, requires_grad=True) C2: tensor(8.4198, requires_grad=True) C3: tensor(0.2019, requires_grad=True)\n",
      "It: 7999 Loss: 62.576507568359375\n",
      "C1: tensor(2.1807, requires_grad=True) C2: tensor(10.2490, requires_grad=True) C3: tensor(1.6759, requires_grad=True)\n",
      "It: 8999 Loss: 33.692138671875\n",
      "C1: tensor(3.5717, requires_grad=True) C2: tensor(11.3729, requires_grad=True) C3: tensor(2.4162, requires_grad=True)\n",
      "It: 9999 Loss: 19.75494956970215\n",
      "C1: tensor(4.6063, requires_grad=True) C2: tensor(12.2303, requires_grad=True) C3: tensor(2.7508, requires_grad=True)\n",
      "It: 10999 Loss: 11.27987289428711\n",
      "C1: tensor(5.5357, requires_grad=True) C2: tensor(12.9694, requires_grad=True) C3: tensor(2.8506, requires_grad=True)\n",
      "It: 11999 Loss: 6.007420539855957\n",
      "C1: tensor(6.3529, requires_grad=True) C2: tensor(13.6193, requires_grad=True) C3: tensor(2.8151, requires_grad=True)\n",
      "It: 12999 Loss: 2.970196485519409\n",
      "C1: tensor(7.0923, requires_grad=True) C2: tensor(14.1673, requires_grad=True) C3: tensor(2.7562, requires_grad=True)\n",
      "It: 13999 Loss: 1.3855547904968262\n",
      "C1: tensor(7.7723, requires_grad=True) C2: tensor(14.5747, requires_grad=True) C3: tensor(2.7075, requires_grad=True)\n",
      "It: 14999 Loss: 0.7471840977668762\n",
      "C1: tensor(8.3948, requires_grad=True) C2: tensor(14.8135, requires_grad=True) C3: tensor(2.6804, requires_grad=True)\n",
      "It: 15999 Loss: 0.2912061810493469\n",
      "C1: tensor(8.9435, requires_grad=True) C2: tensor(14.9159, requires_grad=True) C3: tensor(2.6724, requires_grad=True)\n",
      "It: 16999 Loss: 0.10671661049127579\n",
      "C1: tensor(9.3905, requires_grad=True) C2: tensor(14.9568, requires_grad=True) C3: tensor(2.6708, requires_grad=True)\n",
      "It: 17999 Loss: 0.04250166937708855\n",
      "C1: tensor(9.7127, requires_grad=True) C2: tensor(14.9786, requires_grad=True) C3: tensor(2.6697, requires_grad=True)\n",
      "It: 18999 Loss: 0.026048412546515465\n",
      "C1: tensor(9.8970, requires_grad=True) C2: tensor(14.9910, requires_grad=True) C3: tensor(2.6682, requires_grad=True)\n",
      "It: 19999 Loss: 0.21661363542079926\n",
      "C1: tensor(9.9705, requires_grad=True) C2: tensor(14.9959, requires_grad=True) C3: tensor(2.6679, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21661363542079926"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs1 = NN_H2(1, 40, 2, 3)\n",
    "PINNs1.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1,C2,C3], 'lr': 0.001})\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_1 = []\n",
    "test_loss_1 = []\n",
    "C1_a_list = []\n",
    "C2_a_list = []\n",
    "C3_a_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<20000:\n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs1(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs1(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs1(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_1.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        \n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_a_list.append(C1.detach().item())\n",
    "        C2_a_list.append(C2.detach().item())\n",
    "        C3_a_list.append(C3.detach().item())\n",
    "        print('C1:',C1,'C2:',C2,'C3:',C3)\n",
    "        \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c8ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3acc54f8",
   "metadata": {},
   "source": [
    "## $\\text{GA-PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aab9c93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:44:25.938893Z",
     "start_time": "2024-02-11T09:44:25.932538Z"
    }
   },
   "outputs": [],
   "source": [
    "N_inside = 500\n",
    "N_bound = 10\n",
    "inside_t = lhs(1,N_inside)*(3-0)\n",
    "bound_t = np.zeros((N_bound,1))\n",
    "real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "inside_t = torch.from_numpy(inside_t).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "inside_t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "inside_t = inside_t.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "real_bound = real_bound.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadf4c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:44:25.944434Z",
     "start_time": "2024-02-11T09:44:25.941234Z"
    }
   },
   "outputs": [],
   "source": [
    "C1_b = torch.tensor(1.0, requires_grad=True)\n",
    "C2_b = torch.tensor(1.0, requires_grad=True)\n",
    "C3_b = torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199f787a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-11T09:56:53.687588Z",
     "start_time": "2024-02-11T09:53:49.440858Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0 Loss: 1657.8148193359375\n",
      "C1: tensor(9.9855, requires_grad=True) C2: tensor(14.9964, requires_grad=True) C3: tensor(2.6659, requires_grad=True)\n",
      "It: 999 Loss: 11.710945129394531\n",
      "C1: tensor(8.6211, requires_grad=True) C2: tensor(15.3052, requires_grad=True) C3: tensor(2.3375, requires_grad=True)\n",
      "It: 1999 Loss: 7.066076278686523\n",
      "C1: tensor(8.1632, requires_grad=True) C2: tensor(15.3235, requires_grad=True) C3: tensor(2.5843, requires_grad=True)\n",
      "It: 2999 Loss: 5.364266395568848\n",
      "C1: tensor(8.1963, requires_grad=True) C2: tensor(15.0778, requires_grad=True) C3: tensor(2.6445, requires_grad=True)\n",
      "It: 3999 Loss: 4.03164529800415\n",
      "C1: tensor(8.5992, requires_grad=True) C2: tensor(14.9733, requires_grad=True) C3: tensor(2.6480, requires_grad=True)\n",
      "It: 4999 Loss: 2.4237465858459473\n",
      "C1: tensor(9.1323, requires_grad=True) C2: tensor(14.9570, requires_grad=True) C3: tensor(2.6544, requires_grad=True)\n",
      "It: 5999 Loss: 1.4679369926452637\n",
      "C1: tensor(9.6239, requires_grad=True) C2: tensor(14.9731, requires_grad=True) C3: tensor(2.6570, requires_grad=True)\n",
      "It: 6999 Loss: 0.7993993759155273\n",
      "C1: tensor(9.8367, requires_grad=True) C2: tensor(14.9635, requires_grad=True) C3: tensor(2.6634, requires_grad=True)\n",
      "It: 7999 Loss: 0.2757854759693146\n",
      "C1: tensor(9.8935, requires_grad=True) C2: tensor(14.9685, requires_grad=True) C3: tensor(2.6604, requires_grad=True)\n",
      "It: 8999 Loss: 0.09245795011520386\n",
      "C1: tensor(9.9435, requires_grad=True) C2: tensor(14.9818, requires_grad=True) C3: tensor(2.6647, requires_grad=True)\n",
      "It: 9999 Loss: 0.05842222273349762\n",
      "C1: tensor(9.9679, requires_grad=True) C2: tensor(14.9888, requires_grad=True) C3: tensor(2.6656, requires_grad=True)\n",
      "It: 10999 Loss: 0.036399245262145996\n",
      "C1: tensor(9.9831, requires_grad=True) C2: tensor(14.9929, requires_grad=True) C3: tensor(2.6662, requires_grad=True)\n",
      "It: 11999 Loss: 0.03465387970209122\n",
      "C1: tensor(9.9895, requires_grad=True) C2: tensor(14.9946, requires_grad=True) C3: tensor(2.6663, requires_grad=True)\n",
      "It: 12999 Loss: 0.020847920328378677\n",
      "C1: tensor(9.9934, requires_grad=True) C2: tensor(14.9959, requires_grad=True) C3: tensor(2.6667, requires_grad=True)\n",
      "It: 13999 Loss: 0.06410853564739227\n",
      "C1: tensor(9.9968, requires_grad=True) C2: tensor(14.9973, requires_grad=True) C3: tensor(2.6672, requires_grad=True)\n",
      "It: 14999 Loss: 0.056987933814525604\n",
      "C1: tensor(10.0003, requires_grad=True) C2: tensor(14.9981, requires_grad=True) C3: tensor(2.6673, requires_grad=True)\n",
      "It: 15999 Loss: 0.07950958609580994\n",
      "C1: tensor(10.0028, requires_grad=True) C2: tensor(14.9987, requires_grad=True) C3: tensor(2.6675, requires_grad=True)\n",
      "It: 16999 Loss: 0.01572047919034958\n",
      "C1: tensor(10.0030, requires_grad=True) C2: tensor(14.9992, requires_grad=True) C3: tensor(2.6678, requires_grad=True)\n",
      "It: 17999 Loss: 0.0064181978814303875\n",
      "C1: tensor(10.0045, requires_grad=True) C2: tensor(14.9994, requires_grad=True) C3: tensor(2.6677, requires_grad=True)\n",
      "It: 18999 Loss: 0.015058061107993126\n",
      "C1: tensor(10.0056, requires_grad=True) C2: tensor(14.9994, requires_grad=True) C3: tensor(2.6675, requires_grad=True)\n",
      "It: 19999 Loss: 0.007118212059140205\n",
      "C1: tensor(10.0055, requires_grad=True) C2: tensor(14.9995, requires_grad=True) C3: tensor(2.6676, requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.007118212059140205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs2 = NN_H2(1, 40, 2, 3)\n",
    "PINNs2.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs2.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1_b,C2_b,C3_b], 'lr': 0.001})\n",
    "\n",
    "discriminator = get_discriminator(4, 40, 2, 1)\n",
    "discriminator.cuda()\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in discriminator.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "        \n",
    "optimizer2 = optim.Adam(discriminator.parameters(), lr=5e-3,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "C1_b_list = []\n",
    "C2_b_list = []\n",
    "C3_b_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<20000:\n",
    "    \n",
    "    if it <=1000:    \n",
    "    \n",
    "        ############ loss D ###########\n",
    "        pre_H = PINNs2(train_t)\n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H.detach()),1))\n",
    "        d_real = discriminator(torch.cat((train_t,train_data),1))\n",
    "\n",
    "        loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer2.step()  \n",
    "\n",
    "        ####### loss G#######\n",
    "        pre_H = PINNs2(train_t)  \n",
    "\n",
    "        d_fake = discriminator(torch.cat((train_t,pre_H),1))\n",
    "\n",
    "        loss_L = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - train_data))\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss_L.backward()\n",
    "        optimizer1.step()     \n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound = PINNs2(bound_t)\n",
    "    loss_bound = torch.mean(torch.square(E_bound[:,0:1]-real_bound[:,0:1]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,1:2]-real_bound[:,1:2]))+\\\n",
    "                 torch.mean(torch.square(E_bound[:,2:3]-real_bound[:,2:3]))\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs2(inside_t)\n",
    "    E_inside_x = E_inside[:,0:1]\n",
    "    E_inside_y = E_inside[:,1:2]   \n",
    "    E_inside_z = E_inside[:,2:3]   \n",
    "    \n",
    "    d_x_t = autograd.grad(outputs=E_inside_x, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_y_t = autograd.grad(outputs=E_inside_y, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_y),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "    \n",
    "    d_z_t = autograd.grad(outputs=E_inside_z, inputs=inside_t,\n",
    "                              grad_outputs=torch.ones_like(E_inside_z),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]      \n",
    "\n",
    "    loss_f = torch.mean(torch.square(d_x_t-(C1_b*(E_inside_y-E_inside_x))))+\\\n",
    "             torch.mean(torch.square(d_y_t-(E_inside_x*(C2_b-E_inside_z)-E_inside_y)))+\\\n",
    "             torch.mean(torch.square(d_z_t-(E_inside_x*E_inside_y-C3_b*E_inside_z)))\n",
    "    \n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs2(train_t)\n",
    "    \n",
    "    loss_observation = torch.mean(torch.square(E_observation[:,0:1]-train_data[:,0:1]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,1:2]-train_data[:,1:2]))+\\\n",
    "                       torch.mean(torch.square(E_observation[:,2:3]-train_data[:,2:3]))\n",
    "\n",
    "    loss = loss_bound+loss_f+2*loss_observation\n",
    "    \n",
    "    loss_all_2.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (it+1) % 1000 == 0 or it==0:\n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        \n",
    "        ## 用于PDE的数据\n",
    "        N_inside = 500\n",
    "        N_bound = 10\n",
    "        inside_t = lhs(1,N_inside)*(3-0)\n",
    "        bound_t = np.zeros((N_bound,1))\n",
    "        real_bound = np.concatenate((-8*np.ones((N_bound,1)),7*np.ones((N_bound,1)),27*np.ones((N_bound,1))),axis=1)\n",
    "\n",
    "        inside_t = torch.from_numpy(inside_t).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "        real_bound = torch.from_numpy(real_bound).float()\n",
    "\n",
    "        inside_t.requires_grad_()\n",
    "\n",
    "        ###########GPU###########\n",
    "        inside_t = inside_t.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        real_bound = real_bound.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        C1_b_list.append(C1_b.detach().item())\n",
    "        C2_b_list.append(C2_b.detach().item())\n",
    "        C3_b_list.append(C3_b.detach().item())\n",
    "        print('C1:',C1_b,'C2:',C2_b,'C3:',C3_b)\n",
    "            \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c999fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03309919",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ba74da",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/J1/C1_a_list',C1_a_list)\n",
    "# np.save('../experimental_data/J1/C1_b_list',C1_b_list)\n",
    "# np.save('../experimental_data/J1/C2_a_list',C2_a_list)\n",
    "# np.save('../experimental_data/J1/C2_b_list',C2_b_list)\n",
    "# np.save('../experimental_data/J1/C3_a_list',C3_a_list)\n",
    "# np.save('../experimental_data/J1/C3_b_list',C3_b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed5de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
