{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from models_all import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5b60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 40\n",
    "N_bound_1 = 20\n",
    "N_bound_2 = 10\n",
    "\n",
    "# x,t\n",
    "la = np.array([1,1])\n",
    "lb = np.array([-1,0])\n",
    "\n",
    "traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "bound_t = 0+(1-(0))*lhs(1,N_bound_1)\n",
    "bound_x = -1+(1-(-1))*lhs(1,N_bound_2)\n",
    "\n",
    "x = traindata[:,0:1]\n",
    "t = traindata[:,1:2]\n",
    "\n",
    "x = torch.from_numpy(x).float()\n",
    "t = torch.from_numpy(t).float()\n",
    "bound_x = torch.from_numpy(bound_x).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "\n",
    "x.requires_grad_()\n",
    "t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "bound_x = bound_x.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "x = x.cuda()\n",
    "t = t.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde93128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return np.sin(np.pi * x[:, 0:1]) * np.exp(-x[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "observe_data = np.vstack((np.linspace(-1, 1, num=10), np.full((10), 1))).T\n",
    "observe_y = func(observe_data)\n",
    "observe_data = torch.from_numpy(observe_data).float()\n",
    "observe_y = torch.from_numpy(observe_y).float()\n",
    "\n",
    "n=5\n",
    "np.random.seed(3456)\n",
    "index_a = np.random.randint(0,10,n,)\n",
    "observe_data = observe_data[index_a]\n",
    "observe_y = observe_y[index_a]\n",
    "\n",
    "\n",
    "###########GPU###########\n",
    "observe_y = observe_y.cuda()\n",
    "observe_data = observe_data.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79adbe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test = 2000\n",
    "test_data = lb+(la-lb)*lhs(2,N_test)\n",
    "test_y = func(test_data)\n",
    "test_data = torch.from_numpy(test_data).float()\n",
    "test_y = torch.from_numpy(test_y).float()\n",
    "###########GPU###########\n",
    "test_data = test_data.cuda()\n",
    "test_y = test_y.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd4c6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_l2(u_pred, u_real):\n",
    "\n",
    "    l2 = torch.norm(u_real - u_pred, p=2) / torch.norm(u_real, p=2)\n",
    "    \n",
    "    return l2.item()  # Convert the result back to a Python float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b01aa90",
   "metadata": {},
   "source": [
    "## $\\text{PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfbeb38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "\n",
    "PINNs1 = NN_H2(2, 32, 3, 1)\n",
    "PINNs1.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs1.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C1], 'lr': 0.001})\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_1 = []\n",
    "test_loss_1 = []\n",
    "C1_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<7000:\n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound_1 = PINNs1(torch.cat((bound_x,torch.zeros_like(bound_x)),axis=1))\n",
    "    loss_bound_1 = torch.mean(torch.square(E_bound_1-torch.sin(torch.tensor(np.pi)*bound_x)))\n",
    "\n",
    "    E_bound_2_a = PINNs1(torch.cat((-1*torch.ones_like(bound_t),bound_t),axis=1))\n",
    "    E_bound_2_b = PINNs1(torch.cat((1*torch.ones_like(bound_t),bound_t),axis=1))\n",
    "    loss_bound_2 = torch.mean(torch.square(E_bound_2_a))+\\\n",
    "                   torch.mean(torch.square(E_bound_2_b))\n",
    "\n",
    "    loss_bound = loss_bound_1+loss_bound_2\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs1(torch.cat((x,t),axis=1))\n",
    "\n",
    "    d_t = autograd.grad(outputs=E_inside, inputs=t,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "    d_x = autograd.grad(outputs=E_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "    d_xx = autograd.grad(outputs=d_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(d_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "\n",
    "    loss_f = d_t-C1*d_xx+torch.exp(-t)*(torch.sin(torch.tensor(np.pi)*x)-torch.tensor(np.pi)*torch.tensor(np.pi)*torch.sin(torch.tensor(np.pi)*x))\n",
    "    loss_f = torch.mean(torch.square(loss_f))\n",
    "\n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs1(observe_data)\n",
    "    loss_observation = torch.mean(torch.square(E_observation-observe_y))\n",
    "\n",
    "    loss = loss_bound+loss_f+loss_observation\n",
    "\n",
    "    loss_all_1.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    if (it+1) % 1000 == 0  or it==4999:\n",
    "        \n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        print(C1)\n",
    "        C1_list.append(C1.detach().item())    \n",
    "            \n",
    "        N_train = 40\n",
    "        N_bound_1 = 20\n",
    "        N_bound_2 = 10\n",
    "\n",
    "        # x,t\n",
    "        la = np.array([1,1])\n",
    "        lb = np.array([-1,0])\n",
    "\n",
    "        traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "        bound_t = 0+(1-(0))*lhs(1,N_bound_1)\n",
    "        bound_x = -1+(1-(-1))*lhs(1,N_bound_2)\n",
    "\n",
    "        x = traindata[:,0:1]\n",
    "        t = traindata[:,1:2]\n",
    "\n",
    "        x = torch.from_numpy(x).float()\n",
    "        t = torch.from_numpy(t).float()\n",
    "        bound_x = torch.from_numpy(bound_x).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "\n",
    "        x.requires_grad_()\n",
    "        t.requires_grad_()      \n",
    "        ###########GPU###########\n",
    "        bound_x = bound_x.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        x = x.cuda()\n",
    "        t = t.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        #########  test_loss NRMSE  #########\n",
    "        pre_y = PINNs1(test_data)\n",
    "                 \n",
    "        test_loss = relative_l2(pre_y,test_y)\n",
    "        test_loss_1.append(test_loss)\n",
    "           \n",
    "    it = it + 1        \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80266d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0cba517",
   "metadata": {},
   "source": [
    "## $\\text{GA-PINN}^{\\S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b75131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 40\n",
    "N_bound_1 = 20\n",
    "N_bound_2 = 10\n",
    "\n",
    "# x,t\n",
    "la = np.array([1,1])\n",
    "lb = np.array([-1,0])\n",
    "\n",
    "traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "bound_t = 0+(1-(0))*lhs(1,N_bound_1)\n",
    "bound_x = -1+(1-(-1))*lhs(1,N_bound_2)\n",
    "\n",
    "x = traindata[:,0:1]\n",
    "t = traindata[:,1:2]\n",
    "\n",
    "x = torch.from_numpy(x).float()\n",
    "t = torch.from_numpy(t).float()\n",
    "bound_x = torch.from_numpy(bound_x).float()\n",
    "bound_t = torch.from_numpy(bound_t).float()\n",
    "\n",
    "x.requires_grad_()\n",
    "t.requires_grad_()\n",
    "\n",
    "###########GPU###########\n",
    "bound_x = bound_x.cuda()\n",
    "bound_t = bound_t.cuda()\n",
    "x = x.cuda()\n",
    "t = t.cuda()\n",
    "###########GPU###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "C2 = torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a4f027f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "PINNs2 = NN_H2(2, 32, 3, 1)\n",
    "PINNs2.cuda()\n",
    "\n",
    "# PINNs1.apply(weights_init)\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in PINNs2.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs2.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "\n",
    "optimizer1.add_param_group({'params': [C2], 'lr': 0.001})\n",
    "\n",
    "discriminator = get_discriminator(3, 32, 4, 1)\n",
    "discriminator.cuda()\n",
    "\n",
    "import torch.nn.init as init\n",
    "for name, param in discriminator.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.xavier_uniform_(param)\n",
    "        \n",
    "optimizer2 = optim.Adam(discriminator.parameters(), lr=5e-3,betas=(0.9, 0.999), eps=1e-08, weight_decay=0.001, amsgrad=False)\n",
    "\n",
    "nIter1 = 10000\n",
    "\n",
    "loss_all_2 = []\n",
    "test_loss_2 = []\n",
    "C2_list = []\n",
    "\n",
    "loss1_value = 1\n",
    "it = 0\n",
    "\n",
    "while  it<7000:\n",
    "    \n",
    "    if it <=500:    \n",
    "    \n",
    "        ############ loss D ###########\n",
    "        pre_H = PINNs2(observe_data)\n",
    "\n",
    "        d_fake = discriminator(torch.cat((observe_data,pre_H.detach()),1))\n",
    "        d_real = discriminator(torch.cat((observe_data,observe_y),1))\n",
    "\n",
    "        loss_d = torch.mean(1-d_real)+torch.mean(d_fake)\n",
    "        #loss_d = torch.mean(1-d_real)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        loss_d.backward()\n",
    "        optimizer2.step()  \n",
    "\n",
    "        ####### loss G#######\n",
    "        pre_H = PINNs2(observe_data)  \n",
    "\n",
    "        d_fake = discriminator(torch.cat((observe_data,pre_H),1))\n",
    "\n",
    "        loss_L = torch.mean(1-d_fake)+torch.mean(torch.square(pre_H - observe_y))\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss_L.backward()\n",
    "        optimizer1.step()      \n",
    "    \n",
    "    ##### loss_Bi  ######\n",
    "    E_bound_1 = PINNs2(torch.cat((bound_x,torch.zeros_like(bound_x)),axis=1))\n",
    "    loss_bound_1 = torch.mean(torch.square(E_bound_1-torch.sin(torch.tensor(np.pi)*bound_x)))\n",
    "\n",
    "    E_bound_2_a = PINNs2(torch.cat((-1*torch.ones_like(bound_t),bound_t),axis=1))\n",
    "    E_bound_2_b = PINNs2(torch.cat((1*torch.ones_like(bound_t),bound_t),axis=1))\n",
    "    loss_bound_2 = torch.mean(torch.square(E_bound_2_a))+\\\n",
    "                   torch.mean(torch.square(E_bound_2_b))\n",
    "    #                torch.mean(torch.square(E_bound_2_a-E_bound_2_b))\n",
    "    loss_bound = loss_bound_1+loss_bound_2\n",
    "    \n",
    "    ##### loss f  ######    \n",
    "    E_inside = PINNs2(torch.cat((x,t),axis=1))\n",
    "\n",
    "    d_t = autograd.grad(outputs=E_inside, inputs=t,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "    d_x = autograd.grad(outputs=E_inside, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(E_inside),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "    d_xx = autograd.grad(outputs=d_x, inputs=x,\n",
    "                              grad_outputs=torch.ones_like(d_x),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]  \n",
    "\n",
    "\n",
    "    loss_f = d_t-C2*d_xx+torch.exp(-t)*(torch.sin(torch.tensor(np.pi)*x)-torch.tensor(np.pi)*torch.tensor(np.pi)*torch.sin(torch.tensor(np.pi)*x))\n",
    "    loss_f = torch.mean(torch.square(loss_f))\n",
    "\n",
    "    ##### loss observation  ######        \n",
    "    E_observation = PINNs2(observe_data)\n",
    "    loss_observation = torch.mean(torch.square(E_observation-observe_y))\n",
    "\n",
    "    loss = loss_bound+loss_f+loss_observation\n",
    "\n",
    "    loss_all_2.append(loss.item())\n",
    "    loss1_value = loss.item()\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "        \n",
    "    if (it+1) % 1000 == 0  or it==4999:\n",
    "        \n",
    "        print('It:', it, 'Loss:', loss.item())\n",
    "        print(C2)\n",
    "        C2_list.append(C2.detach().item())     \n",
    "        \n",
    "        N_train = 40\n",
    "        N_bound_1 = 20\n",
    "        N_bound_2 = 10\n",
    "\n",
    "        # x,t\n",
    "        la = np.array([1,1])\n",
    "        lb = np.array([-1,0])\n",
    "\n",
    "        traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "        bound_t = 0+(1-(0))*lhs(1,N_bound_1)\n",
    "        bound_x = -1+(1-(-1))*lhs(1,N_bound_2)\n",
    "\n",
    "        x = traindata[:,0:1]\n",
    "        t = traindata[:,1:2]\n",
    "\n",
    "        x = torch.from_numpy(x).float()\n",
    "        t = torch.from_numpy(t).float()\n",
    "        bound_x = torch.from_numpy(bound_x).float()\n",
    "        bound_t = torch.from_numpy(bound_t).float()\n",
    "\n",
    "        x.requires_grad_()\n",
    "        t.requires_grad_()      \n",
    "        ###########GPU###########\n",
    "        bound_x = bound_x.cuda()\n",
    "        bound_t = bound_t.cuda()\n",
    "        x = x.cuda()\n",
    "        t = t.cuda()\n",
    "        ###########GPU###########\n",
    "        \n",
    "        #########  test_loss NRMSE  #########\n",
    "        pre_y = PINNs2(test_data)\n",
    "                 \n",
    "        test_loss = relative_l2(pre_y,test_y)\n",
    "        test_loss_2.append(test_loss)\n",
    "           \n",
    "    it = it + 1  \n",
    "    \n",
    "loss1_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e642bfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18014997",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551da164",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db9a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:17:09.994496Z",
     "start_time": "2024-10-28T11:17:09.989470Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.save('../experimental_data/J2/test_loss_1',test_loss_1)\n",
    "# np.save('../experimental_data/J2/test_loss_2',test_loss_2)\n",
    "# np.save('../experimental_data/J2/loss_all_1',loss_all_1)\n",
    "# np.save('../experimental_data/J2/loss_all_2',loss_all_2)\n",
    "# np.save('../experimental_data/J2/C1_list',C1_list)\n",
    "# np.save('../experimental_data/J2/C2_list',C2_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a72450",
   "metadata": {},
   "source": [
    "### Epochs NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca8270",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-28T11:17:10.347598Z",
     "start_time": "2024-10-28T11:17:10.289099Z"
    }
   },
   "outputs": [],
   "source": [
    "print('NRMSE_A',test_loss_1[-1],'NRMSE_B',test_loss_2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82039627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7e5e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
